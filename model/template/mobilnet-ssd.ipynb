{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Mobilenetv2 + SSD.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbsreEfjnQtP",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implementation of MobileNetv2+SSD<br>\n",
    "This is an implementation of the MobileNetv2 + SSD architecture for a relatively simpler task of determining bounding boxes for MNIST images embedded in a box. Each box contains only one digit(28x28 MNIST embedded into a 224x224 box) as of now, but the number of predictions per image can be expanded easily (the training outputs need to modified). Also, no data augmentation has been used till now (Colab kept crashing when I increased the dataset size beyond 1000, so the initial amount of data present was sufficient. The crashes might have been due to high traffic, but I haven't confirmed it).<p>\n",
    "In the earlier implementation, the ground truth data contained information about only one bounding box, which meant only one prediction per image ( reference https://colab.research.google.com/github/rs9899/mySSDimplementation/blob/master/MobileNetSSD_v2.ipynb#scrollTo=xWBzDsvkDqx5). For me, it also reduced the training signal and the model was overfitting. So I changed the outputs to a prediction for each default box (as it should be, from what I understood from the SSD paper). Although the initial implementation is good for the purposes for understanding the model.\n",
    "\n",
    "Comments mentioned throughout the code mention what needs to change if the model inputs or outputs are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdL2AL8yAi00",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_hvSY3X-AeFP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "1039d725-6ddc-4032-f23c-a33ccd056bc8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import numpy.matlib\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import bottleneck"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFmrlFJ8uKCe",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define Bottleneck Residual layer for MobileNet<br>\n",
    "Using the same parameters as mentioned in the paper"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xmwhyyS7CFyK",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class Bottleneck(keras.Model):\n",
    "  def __init__(\n",
    "      self,\n",
    "      expansion,\n",
    "      stride,\n",
    "      block_id,\n",
    "      filters,\n",
    "      alpha=1,\n",
    "      ):\n",
    "    super(Bottleneck,self).__init__(name = \"Bottleneck_\" + block_id)\n",
    "    self.stride = stride\n",
    "    self.expansion = expansion\n",
    "    self.alpha = alpha\n",
    "    self.output_channels = self.alpha * filters\n",
    "    self.out = None # there was some problem with the eager execution\n",
    "\n",
    "    prefix =  'Bottleneck_{}_'.format(block_id)\n",
    "    self.prefix = prefix\n",
    "    # expansion\n",
    "    self.expand_BN = layers.BatchNormalization(name = prefix + 'expand_BN')\n",
    "    self.expand_ReLU = layers.ReLU(max_value=6, name = prefix + 'expand_ReLU')\n",
    "\n",
    "    #conv\n",
    "    self.Conv = layers.DepthwiseConv2D(\n",
    "        kernel_size = 3,\n",
    "        padding='same',\n",
    "        strides = self.stride,\n",
    "        use_bias = False,\n",
    "        name = prefix + 'conv')\n",
    "    self.Conv_BN = layers.BatchNormalization(name = prefix + 'conv_BN')\n",
    "    self.Conv_ReLU = layers.ReLU(max_value=6, name = prefix + 'conv_ReLU')\n",
    "\n",
    "    #project\n",
    "    self.project = layers.Conv2D(\n",
    "        filters = self.output_channels,\n",
    "        kernel_size = 1,\n",
    "        use_bias = False,\n",
    "        name = 'contract')\n",
    "    self.project_BN = layers.BatchNormalization(name = prefix + 'contract_BN')\n",
    "\n",
    "    # dimensions need to be the same for residual connection\n",
    "    self.residual = layers.Add(name=prefix + 'residual')\n",
    "  \n",
    "  def build(self, input_shape):\n",
    "    self.d = input_shape[-1]\n",
    "    \n",
    "    self.expand = layers.Conv2D(\n",
    "        filters = self.expansion*self.d,\n",
    "        kernel_size = 1,\n",
    "        use_bias = False,\n",
    "        name = self.prefix+'expand')\n",
    "\n",
    "      \n",
    "  def call(self, inputs):\n",
    "\n",
    "    x = self.expand(inputs)\n",
    "    x = self.expand_BN(x)\n",
    "    x = self.expand_ReLU(x)\n",
    "    self.out = x\n",
    "    \n",
    "    x = self.Conv(x)\n",
    "    x = self.Conv_BN(x)\n",
    "    x = self.Conv_ReLU(x)\n",
    "\n",
    "    x = self.project(x)\n",
    "    x = self.project_BN(x)\n",
    "\n",
    "    if self.output_channels == self.d and self.stride == 1:\n",
    "      x = self.residual([inputs,x])\n",
    "\n",
    "    return x\n",
    "\n",
    "  def model(self):\n",
    "      x = keras.Input(shape=(28,28,3))\n",
    "      return keras.Model(inputs=[x], outputs=self.call(x))"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfMYYpWpuQj4",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define MobileNetv2<br>\n",
    "Same components as mentioned in the paper (the input image dimensions are a bit different)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VYGagWE8T2Et",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#using the architecture mentioned in the paper\n",
    "class MobileNetv2(keras.Model):\n",
    "  def __init__(self, k = 11):\n",
    "    super(MobileNetv2,self).__init__()\n",
    "    self.conv_inp = layers.Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        strides = (2,2),\n",
    "        padding='valid',\n",
    "        use_bias = False,\n",
    "        name = 'conv'\n",
    "    )\n",
    "    self.k = k    \n",
    "\n",
    "    self.pad = layers.ZeroPadding2D(padding=2,name='pad')\n",
    "    self.BN = layers.BatchNormalization(name='BN')\n",
    "    self.ReLU = layers.ReLU(max_value = 6, name = 'ReLU')\n",
    "    \n",
    "    self.B1_1 = Bottleneck(expansion = 1, filters = 16, stride = 1, block_id = 'B1_1')\n",
    "\n",
    "    self.B2_1 = Bottleneck(expansion = 6, filters = 24, stride = 2, block_id = 'B2_1')\n",
    "    self.B2_2 = Bottleneck(expansion = 6, filters = 24, stride = 1, block_id = 'B2_2')\n",
    "\n",
    "    self.B3_1 = Bottleneck(expansion = 6, filters = 32, stride = 2, block_id = 'B3_1')\n",
    "    self.B3_2 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_2')\n",
    "    self.B3_3 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_3')\n",
    "\n",
    "    self.B4_1 = Bottleneck(expansion = 6, filters = 64, stride = 2, block_id = 'B4_1')\n",
    "    self.B4_2 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_2')\n",
    "    self.B4_3 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_3')\n",
    "    self.B4_4 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_4')\n",
    "\n",
    "    self.B5_1 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_1')\n",
    "    self.B5_2 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_2')\n",
    "    self.B5_3 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_3')\n",
    "\n",
    "    self.B6_1 = Bottleneck(expansion = 6, filters = 160, stride = 2, block_id = 'B6_1')\n",
    "    self.B6_2 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_2')\n",
    "    self.B6_3 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_3')\n",
    "\n",
    "    self.B7_1 = Bottleneck(expansion = 6, filters = 320, stride = 1, block_id = 'B7_1')\n",
    "\n",
    "    self.conv_out = layers.Conv2D(\n",
    "        filters = 1280,\n",
    "        kernel_size = 1,\n",
    "        strides = (1,1),\n",
    "        use_bias = False,\n",
    "        name = 'conv_out'\n",
    "    )\n",
    "    self.avgpool = layers.AveragePooling2D(\n",
    "        pool_size = (7,7),\n",
    "        name='avg_pool'\n",
    "        )\n",
    "    \n",
    "    self.conv_seg = layers.Conv2D(\n",
    "        filters = self.k,\n",
    "        kernel_size = 1,\n",
    "        strides = (1,1),\n",
    "        use_bias = False,\n",
    "        name = 'conv_seg'\n",
    "    )\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.conv_inp(inputs)\n",
    "    x = self.BN(x)\n",
    "    x = self.ReLU(x)\n",
    "\n",
    "    x = self.B1_1(x)\n",
    "    x = self.B2_1(x)\n",
    "    x = self.B2_2(x)\n",
    "\n",
    "    x = self.B3_1(x)\n",
    "    x = self.B3_2(x)\n",
    "    x = self.B3_3(x)\n",
    "    \n",
    "    x = self.B4_1(x)\n",
    "    x = self.B4_2(x)\n",
    "    x = self.B4_3(x)\n",
    "    x = self.B4_4(x)\n",
    "    \n",
    "    x = self.B5_1(x)\n",
    "    x = self.B5_2(x)\n",
    "    x = self.B5_3(x)\n",
    "    \n",
    "    x = self.B6_1(x)\n",
    "    x = self.B6_2(x)\n",
    "    x = self.B6_3(x)\n",
    "    \n",
    "    x = self.B7_1(x)\n",
    "\n",
    "    x = self.conv_out(x)\n",
    "    x = self.avgpool(x)\n",
    "    c4 = self.conv_seg(x)\n",
    "\n",
    "    return c4\n",
    "\n",
    "  def model(self):\n",
    "      x = keras.Input(shape=(224,224,3))\n",
    "\n",
    "      return keras.Model(inputs=x, outputs=self.call(x))"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "05i7363EYwmP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "outputId": "d8434d3b-e85a-4481-b5bd-15751d6e9140",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "MobileNetv2().model().summary()"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 111, 111, 32)      864       \n",
      "_________________________________________________________________\n",
      "BN (BatchNormalization)      (None, 111, 111, 32)      128       \n",
      "_________________________________________________________________\n",
      "ReLU (ReLU)                  (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "Bottleneck_B1_1 (Bottleneck) (None, 111, 111, 16)      2144      \n",
      "_________________________________________________________________\n",
      "Bottleneck_B2_1 (Bottleneck) (None, 56, 56, 24)        5568      \n",
      "_________________________________________________________________\n",
      "Bottleneck_B2_2 (Bottleneck) (None, 56, 56, 24)        9456      \n",
      "_________________________________________________________________\n",
      "Bottleneck_B3_1 (Bottleneck) (None, 28, 28, 32)        10640     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B3_2 (Bottleneck) (None, 28, 28, 32)        15680     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B3_3 (Bottleneck) (None, 28, 28, 32)        15680     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B4_1 (Bottleneck) (None, 14, 14, 64)        21952     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B4_2 (Bottleneck) (None, 14, 14, 64)        55936     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B4_3 (Bottleneck) (None, 14, 14, 64)        55936     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B4_4 (Bottleneck) (None, 14, 14, 64)        55936     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B5_1 (Bottleneck) (None, 14, 14, 96)        68352     \n",
      "_________________________________________________________________\n",
      "Bottleneck_B5_2 (Bottleneck) (None, 14, 14, 96)        120768    \n",
      "_________________________________________________________________\n",
      "Bottleneck_B5_3 (Bottleneck) (None, 14, 14, 96)        120768    \n",
      "_________________________________________________________________\n",
      "Bottleneck_B6_1 (Bottleneck) (None, 7, 7, 160)         157888    \n",
      "_________________________________________________________________\n",
      "Bottleneck_B6_2 (Bottleneck) (None, 7, 7, 160)         324160    \n",
      "_________________________________________________________________\n",
      "Bottleneck_B6_3 (Bottleneck) (None, 7, 7, 160)         324160    \n",
      "_________________________________________________________________\n",
      "Bottleneck_B7_1 (Bottleneck) (None, 7, 7, 320)         478400    \n",
      "_________________________________________________________________\n",
      "conv_out (Conv2D)            (None, 7, 7, 1280)        409600    \n",
      "_________________________________________________________________\n",
      "avg_pool (AveragePooling2D)  (None, 1, 1, 1280)        0         \n",
      "_________________________________________________________________\n",
      "conv_seg (Conv2D)            (None, 1, 1, 11)          14080     \n",
      "=================================================================\n",
      "Total params: 2,268,096\n",
      "Trainable params: 2,236,480\n",
      "Non-trainable params: 31,616\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "II03ZRu17FnE",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Defining SSD<br>\n",
    "The default number of boxes per layer and resolution of each layer is different, since we are working with MNIST data and 224x224 image sizes.<p>\n",
    "To change the number of boxes per layer and layerWidths, some constraints need to be kept in mind which are mentioned in the later sections"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aYD2gfR9O8L0",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class SSD(keras.Model):\n",
    "  def __init__(self, numBoxes=[4,6,6,6,4,4], layerWidth=[28,14,7,4,2,1], k = 10+1+4):\n",
    "    super(SSD,self).__init__()\n",
    "    self.classes = k\n",
    "    self.featureMaps = 6\n",
    "    self.MobileNet = MobileNetv2(k=k)\n",
    "    self.numBoxes = numBoxes\n",
    "    self.layerWidth = layerWidth\n",
    "    self.features = [None for _ in range(self.featureMaps)]\n",
    "    self.classifiers = [None for _ in range(self.featureMaps)]\n",
    "    \n",
    "    self.conv1_1 = layers.Conv2D(256,1,name='SSD_conv_1_1')\n",
    "    self.conv1_2 = layers.Conv2D(512,3,strides=(2,2),padding='same',name='SSD_conv_1_2')\n",
    "\n",
    "    self.conv2_1 = layers.Conv2D(128,1,name='SSD_conv_2_1')\n",
    "    self.conv2_2 = layers.Conv2D(256,3,strides=(2,2),padding='same',name='SSD_conv_2_2')\n",
    "    \n",
    "    self.conv3_1 = layers.Conv2D(128,1,name='SSD_conv_3_1')\n",
    "    self.conv3_2 = layers.Conv2D(256,3,strides=(1,1),name='SSD_conv_3_2')\n",
    "    \n",
    "    self.conv4_1 = layers.Conv2D(128,1,name='SSD_conv_4_1')\n",
    "    self.conv4_2 = layers.Conv2D(256,2,strides=(1,1),name='SSD_conv_4_2') # changed the kernel size to 2 since the output of the previous layer has width 3\n",
    "\n",
    "    self.conv = []\n",
    "    self.reshape = []\n",
    "    for i in range(self.featureMaps):\n",
    "      self.conv.append(layers.Conv2D(self.numBoxes[i]*self.classes,3,padding='same',name='Classification_'+str(i)))\n",
    "      self.reshape.append(layers.Reshape((self.layerWidth[i]* self.layerWidth[i] * self.numBoxes[i],self.classes),name='Reshape_classification_'+str(i)))\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.MobileNet.build(input_shape)\n",
    "  \n",
    "  def call(self,inputs):\n",
    "    x = inputs\n",
    "    x = self.MobileNet(x)\n",
    "\n",
    "    # get the convolved images at different resolutions\n",
    "    self.features[0] = self.MobileNet.get_layer('Bottleneck_B4_1').out\n",
    "    self.features[1] = self.MobileNet.get_layer('Bottleneck_B5_3').out\n",
    "    self.features[2] = self.conv1_2(self.conv1_1(self.features[1]))\n",
    "    self.features[3] = self.conv2_2(self.conv2_1(self.features[2]))\n",
    "    self.features[4] = self.conv3_2(self.conv3_1(self.features[3]))\n",
    "    self.features[5] = self.conv4_2(self.conv4_1(self.features[4]))\n",
    "\n",
    "    for i in range(self.featureMaps):\n",
    "    # for each feature map, create predictions according to the number of boxes for that layer and the number of output channels\n",
    "      x = self.conv[i](self.features[i])\n",
    "      x = self.reshape[i](x)\n",
    "      self.classifiers[i] = x\n",
    "    \n",
    "    # concatenate all the classifiers\n",
    "    x = layers.concatenate(self.classifiers, axis = -2, name='concatenate')\n",
    "    return x\n",
    "\n",
    "\n",
    "  def model(self):\n",
    "      x = keras.Input(shape=(224,224,3))\n",
    "\n",
    "      return keras.Model(inputs=x, outputs=self.call(x))"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "29A_FW-GxK4t",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "NUM_CLASSES = 10\n",
    "# the first 2 dimensions should be equal to width of the output from the bottleneck expand ReLU at the (4,1) and (5,3) respectively.\n",
    "# the dimensions after the second one are determined by the convolutions written inside the SSD (conv1_2, conv2_2, conv3_3, conv4_2)\n",
    "layerWidths = [28,14,7,4,2,1]\n",
    "numBoxes = [3,3,3,3,3,3]\n",
    "assert len(numBoxes) == len(layerWidths) # numBoxes for each layer and each layer has a specific width\n",
    "outputChannels = NUM_CLASSES + 1 + 4 # 10 classes + background + cx,cy,h,w\n",
    "assert outputChannels - NUM_CLASSES == 5"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FmOfPVIjCkuP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "5fdfe35e-e5d8-4f1f-c112-da87335a2f74",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model = SSD(numBoxes=numBoxes, layerWidth=layerWidths, k = outputChannels)\n",
    "model.model().summary()"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv (Conv2D)                   (None, 111, 111, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "BN (BatchNormalization)         (None, 111, 111, 32) 128         conv[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "ReLU (ReLU)                     (None, 111, 111, 32) 0           BN[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B1_1 (Bottleneck)    (None, 111, 111, 16) 2144        ReLU[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B2_1 (Bottleneck)    (None, 56, 56, 24)   5568        Bottleneck_B1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B2_2 (Bottleneck)    (None, 56, 56, 24)   9456        Bottleneck_B2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B3_1 (Bottleneck)    (None, 28, 28, 32)   10640       Bottleneck_B2_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B3_2 (Bottleneck)    (None, 28, 28, 32)   15680       Bottleneck_B3_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B3_3 (Bottleneck)    (None, 28, 28, 32)   15680       Bottleneck_B3_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B4_1 (Bottleneck)    (None, 14, 14, 64)   21952       Bottleneck_B3_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B4_2 (Bottleneck)    (None, 14, 14, 64)   55936       Bottleneck_B4_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B4_3 (Bottleneck)    (None, 14, 14, 64)   55936       Bottleneck_B4_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B4_4 (Bottleneck)    (None, 14, 14, 64)   55936       Bottleneck_B4_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B5_1 (Bottleneck)    (None, 14, 14, 96)   68352       Bottleneck_B4_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B5_2 (Bottleneck)    (None, 14, 14, 96)   120768      Bottleneck_B5_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B5_3_expand (Conv2D) (None, 14, 14, 576)  55296       Bottleneck_B5_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B5_3_expand_BN (Batc (None, 14, 14, 576)  2304        Bottleneck_B5_3_expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B5_3_expand_ReLU (Re (None, 14, 14, 576)  0           Bottleneck_B5_3_expand_BN[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_1_1 (Conv2D)           (None, 14, 14, 256)  147712      Bottleneck_B5_3_expand_ReLU[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_1_2 (Conv2D)           (None, 7, 7, 512)    1180160     SSD_conv_1_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_2_1 (Conv2D)           (None, 7, 7, 128)    65664       SSD_conv_1_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_2_2 (Conv2D)           (None, 4, 4, 256)    295168      SSD_conv_2_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_3_1 (Conv2D)           (None, 4, 4, 128)    32896       SSD_conv_2_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B4_1_expand (Conv2D) (None, 28, 28, 192)  6144        Bottleneck_B3_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_3_2 (Conv2D)           (None, 2, 2, 256)    295168      SSD_conv_3_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B4_1_expand_BN (Batc (None, 28, 28, 192)  768         Bottleneck_B4_1_expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_4_1 (Conv2D)           (None, 2, 2, 128)    32896       SSD_conv_3_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_B4_1_expand_ReLU (Re (None, 28, 28, 192)  0           Bottleneck_B4_1_expand_BN[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "SSD_conv_4_2 (Conv2D)           (None, 1, 1, 256)    131328      SSD_conv_4_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Classification_0 (Conv2D)       (None, 28, 28, 45)   77805       Bottleneck_B4_1_expand_ReLU[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Classification_1 (Conv2D)       (None, 14, 14, 45)   233325      Bottleneck_B5_3_expand_ReLU[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Classification_2 (Conv2D)       (None, 7, 7, 45)     207405      SSD_conv_1_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Classification_3 (Conv2D)       (None, 4, 4, 45)     103725      SSD_conv_2_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Classification_4 (Conv2D)       (None, 2, 2, 45)     103725      SSD_conv_3_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Classification_5 (Conv2D)       (None, 1, 1, 45)     103725      SSD_conv_4_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_classification_0 (Resha (None, 2352, 15)     0           Classification_0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_classification_1 (Resha (None, 588, 15)      0           Classification_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_classification_2 (Resha (None, 147, 15)      0           Classification_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_classification_3 (Resha (None, 48, 15)       0           Classification_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_classification_4 (Resha (None, 12, 15)       0           Classification_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_classification_5 (Resha (None, 3, 15)        0           Classification_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3150, 15)     0           Reshape_classification_0[0][0]   \n",
      "                                                                 Reshape_classification_1[0][0]   \n",
      "                                                                 Reshape_classification_2[0][0]   \n",
      "                                                                 Reshape_classification_3[0][0]   \n",
      "                                                                 Reshape_classification_4[0][0]   \n",
      "                                                                 Reshape_classification_5[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 3,507,342\n",
      "Trainable params: 3,492,494\n",
      "Non-trainable params: 14,848\n",
      "__________________________________________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RA7NxfQ7_G6",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creating boxes and IoU"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yRYi7Ez7UzpH",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# I have used less varying custom scales and aspect ratios here, since the dataset is already uniform\n",
    "#IMPORTANT: before changing the scales and aspect ratios, read the comment below\n",
    "\n",
    "# number of scales is equal to the number of different resolutions ie num of layer widths\n",
    "# for a given resolution, we have different aspect ratios\n",
    "# num(scales) = num(layerWidth) = num(numBoxes) and num(asp_ratios) = numBoxes[i]\n",
    "MinScale = .1 # Min and Max scale given as percentage\n",
    "MaxScale = 1.5\n",
    "scales = [ MinScale + x/len(layerWidths) * (MaxScale-MinScale) for x in range(len(layerWidths)) ]\n",
    "scales = scales[::-1] # reversing the order because the layerWidths go from high to low (lower to higher resoltuion)\n",
    "\n",
    "asp = [0.5,1.0,1.5]\n",
    "asp1 = [x**0.5 for x in asp]\n",
    "asp2 = [1/x for x in asp1]"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RwR_TIbzYCix",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "IMG_SIZE = 224"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wA_IhnyrUl4S",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "af7460ef-2baf-4430-c1fd-bb068709e5fe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# should be equal to the 1st dimension in the output layer of the SSD model\n",
    "BOXES = sum([a*a*b for a,b in zip(layerWidths,numBoxes)])\n",
    "centres = np.zeros((BOXES,2))\n",
    "hw = np.zeros((BOXES,2))\n",
    "boxes = np.zeros((BOXES,4))\n",
    "print(BOXES)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "3150\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9A1xGMrXVX18",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# calculating the default box centres and height, width\n",
    "idx = 0\n",
    "\n",
    "for gridSize, numBox, scale in zip(layerWidths,numBoxes,scales):\n",
    "  step_size = IMG_SIZE*1.0/gridSize\n",
    "  for i in range(gridSize):\n",
    "    for j in range(gridSize):\n",
    "      pos = idx + (i*gridSize+j) * numBox\n",
    "      # centre is the same for all aspect ratios(=numBox)\n",
    "      centres[ pos : pos + numBox , :] = i*step_size + step_size/2, j*step_size + step_size/2\n",
    "      # height and width vary according to the scale and aspect ratio\n",
    "      # zip asepct ratios and then scale them by the scaling factor\n",
    "      hw[ pos : pos + numBox , :] = np.multiply(gridSize*scale, np.squeeze(np.dstack([asp1,asp2]),axis=0))[:numBox,:]\n",
    "\n",
    "  idx += gridSize*gridSize*numBox "
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xp9CrasJhGXI",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# (x,y) co-ordinates of top left and bottom right\n",
    "# This actually is not used anywhere. centres[] and hw[] are a good enough substitute\n",
    "boxes[:,0] = centres[:,0] - hw[:,0]/2\n",
    "boxes[:,1] = centres[:,1] - hw[:,1]/2\n",
    "boxes[:,2] = centres[:,0] + hw[:,0]/2\n",
    "boxes[:,3] = centres[:,1] + hw[:,1]/2"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TJSIPHPMh3N2",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# calculate IoU for a set of search boxes and default boxes\n",
    "def IoU(box1, box2):\n",
    "  box1 = box1.astype(np.float64)\n",
    "  box2 = box2.astype(np.float64)\n",
    "  # find the left and right co-ordinates of the edges. Min should be less than Max for non zero overlap\n",
    "  xmin = np.maximum(box1[:,0],box2[:,0])\n",
    "  xmax = np.minimum(box1[:,2],box2[:,2])\n",
    "  ymin = np.maximum(box1[:,1],box2[:,1])\n",
    "  ymax = np.minimum(box1[:,3],box2[:,3])\n",
    "\n",
    "  intersection = np.abs(np.maximum(xmax-xmin,0) * np.maximum(ymax-ymin,0))\n",
    "  boxArea1 = np.abs((box1[:,2] - box1[:,0]) * (box1[:,3] - box1[:,1]))\n",
    "  boxArea2 = np.abs((box2[:,2] - box2[:,0]) * (box2[:,3] - box2[:,1]))\n",
    "  unionArea = boxArea1 + boxArea2 - intersection\n",
    "  assert (unionArea > 0).all()\n",
    "  iou = intersection / unionArea\n",
    "\n",
    "  return iou"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iOcpxxIQipbA",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# give the index of the box correpsonding to the IoUs > threshold (=0.5) \n",
    "def bestIoU(searchBox):\n",
    "  return np.argwhere(IoU(numpy.matlib.repmat(searchBox,BOXES,1), boxes) > 0.5)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm2k4c5Ik_BX",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h07BGB7-k9te",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "TRAINSIZE = 600\n",
    "TESTSIZE = 100"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wkZPTKgGq08N",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train[:TRAINSIZE , : , :]\n",
    "y_train = y_train[:TRAINSIZE]\n",
    "x_test = x_test[:TESTSIZE , : , :]\n",
    "y_test = y_test[:TESTSIZE]"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PEgx1Sdcq7yJ",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# take mnist x and y pairs and convert to input, output pairs for the MobileNetv2+SSD model\n",
    "def convert(x,y):\n",
    "  MNIST_SIZE = x.shape[-1]\n",
    "  # create a 2D array of top left corners for the mnist image to be placed\n",
    "  corner = np.random.randint(IMG_SIZE - MNIST_SIZE, size=(x.shape[0],2))\n",
    "\n",
    "  # create a blank canvas for the input with the required dimension\n",
    "  input = np.zeros((x.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "  # replacing a part by RGB version of MNIST\n",
    "  for i in range(x.shape[0]):\n",
    "    lx = int(corner[i,0])\n",
    "    ly = int(corner[i,1])\n",
    "    input[i,lx:lx + MNIST_SIZE, ly:ly+MNIST_SIZE,:] = np.repeat(np.expand_dims(np.array(x[i,:,:]),axis=-1),3,axis=-1)\n",
    "\n",
    "  # for each default box, there are 5 values: class number and delta cx,cy,h,w\n",
    "  output = np.zeros((y.shape[0],BOXES,1+4))\n",
    "  output[:,:,0] = NUM_CLASSES # defaulting class labels for all boxes to background initially\n",
    "  for i in range(x.shape[0]):\n",
    "    bbox = np.zeros(4)\n",
    "    bbox[:2] = corner[i]\n",
    "    bbox[2:] = corner[i] + (MNIST_SIZE,MNIST_SIZE)\n",
    "    # for all default boxes which have IoU > threshold, set the delta values and class number\n",
    "    box_idx = bestIoU(bbox).astype(np.uint16)\n",
    "    output[i,box_idx,0] = y[i]\n",
    "    output[i,box_idx,1] = (bbox[0] + bbox[2])/2.0 - centres[box_idx,0]\n",
    "    output[i,box_idx,2] = (bbox[1] + bbox[3])/2.0 - centres[box_idx,1]\n",
    "    output[i,box_idx,3] = MNIST_SIZE - hw[box_idx,0]\n",
    "    output[i,box_idx,4] = MNIST_SIZE - hw[box_idx,1]\n",
    "\n",
    "  return input, output\n"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sk_z17wV3Bj5",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "test_x, test_y = convert(x_test,y_test)\n",
    "train_x, train_y = convert(x_train,y_train)"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NAwnJnu4qE0P",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "outputId": "27116f08-73e6-42e7-c8d8-daac27654afc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# checking if the inputs prepared are correct or not\n",
    "r = np.random.randint(0,train_x.shape[0])\n",
    "img = train_x[r,:,:,:].copy()\n",
    "img_y = train_y[r]\n",
    "\n",
    "im = np.array(Image.fromarray(img.astype(np.uint8)))\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(im)\n",
    "\n",
    "# find all boxes where class label is not background\n",
    "idx = np.argwhere(img_y[:,0] != NUM_CLASSES)[:,0]\n",
    "print('Number of boxes with IoU > 0.5:',idx.shape[0])\n",
    "print('Green box: ground truth. Red box: default boxes with IoU > threshold')\n",
    "\n",
    "#calculating the ground truth bounding boxes\n",
    "gt = np.zeros(4,dtype=np.uint16)\n",
    "gt[:2] = (img_y[idx[0],1:3] + centres[idx[0],:2])\n",
    "gt[2:] = (img_y[idx[0],3:] + hw[idx[0],:])\n",
    "\n",
    "# for some reason, x and y are inverted\n",
    "rect = patches.Rectangle((gt[1]-gt[3]/2,gt[0]-gt[2]/2),gt[3],gt[2],linewidth=5,edgecolor='g',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# showing all the boxes with IoU > 0.5\n",
    "for i in idx:\n",
    "  rect = patches.Rectangle((centres[i][1]-hw[i,1]/2,centres[i][0]-hw[i,0]/2),hw[i,1],hw[i,0],linewidth=1,edgecolor='r',facecolor='none')\n",
    "  ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Number of boxes with IoU > 0.5: 6\n",
      "Green box: ground truth. Red box: default boxes with IoU > threshold\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1nI7mXjS8zA9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "88b50f5a-8931-4f30-eb69-f211e964d690",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "print(train_dataset.element_spec)\n",
    "print(test_dataset.element_spec)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oyX8dnwQ8_1k",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "BATCH_SIZE = 10\n",
    "SHUFFLE_BUFFER_SIZE = 60\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE,drop_remainder=True)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EeBg_g29GLU",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LOSS FUNCTION<br>\n",
    "Hard negative mining hasn't been done here<br>\n",
    "Initial idea was to assign weights to background classes, but there is some problem in that approach"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rMEpljzd9CxT",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# label is not required here in the standard implementation\n",
    "# calculate the smooth L1 loss\n",
    "def smoothL1(x, y, label):\n",
    "  diff = K.abs(x-y)  #* K.switch(label == 10, label*1.0/BOXES, label)\n",
    "  result = K.switch(diff < 1, 0.5*diff**2, diff-0.5)\n",
    "  return K.mean(result)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8fSUhh8O_DsK",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def confidenceLoss(y,label):\n",
    "  unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(label, y)\n",
    "  # class_weights = tf.constant([[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0/BOXES]]*BOXES])\n",
    "  # weights = tf.reduce_sum(class_weights * y, axis = -1)\n",
    "  # weighted_loss = unweighted_loss * weights\n",
    "  return K.mean(unweighted_loss)"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gn0xh6OX_BvN",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def Loss(gt, y):\n",
    "  # shape of y is n * BOXES * output_channels\n",
    "  # shape of gt is n * BOXES * 5 \n",
    "  loss = 0\n",
    "  # localisation loss\n",
    "  loss += smoothL1(y[:, :, -4:], gt[:, :, -4:], gt[:, :, 0:1])\n",
    "  # confidence loss\n",
    "  loss += confidenceLoss(y[:, :, :-4], tf.cast(gt[:, :, 0], tf.int32))\n",
    "  return loss"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A8_O3V8DB_Gk",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),loss=Loss)"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z7pp6Fp9DDWm",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "39ca0340-fe39-4016-da7d-1ca95148010b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "history = model.fit(train_dataset, epochs=25, validation_data=test_dataset)"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Layer ssd is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
      "60/60 [==============================] - 11s 181ms/step - loss: 0.3415 - val_loss: 0.2681\n",
      "Epoch 2/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0890 - val_loss: 0.0674\n",
      "Epoch 3/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0528 - val_loss: 0.0564\n",
      "Epoch 4/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0457 - val_loss: 0.0455\n",
      "Epoch 5/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0764 - val_loss: 0.0467\n",
      "Epoch 6/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0215 - val_loss: 0.0264\n",
      "Epoch 7/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0241 - val_loss: 0.0191\n",
      "Epoch 8/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0384 - val_loss: 0.0180\n",
      "Epoch 9/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0250 - val_loss: 0.0160\n",
      "Epoch 10/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0333 - val_loss: 0.0145\n",
      "Epoch 11/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 12/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0207 - val_loss: 0.0144\n",
      "Epoch 13/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 14/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0162 - val_loss: 0.0130\n",
      "Epoch 15/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 16/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 17/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 18/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 19/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 20/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 21/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 22/25\n",
      "60/60 [==============================] - 10s 166ms/step - loss: 0.0114 - val_loss: 0.0149\n",
      "Epoch 23/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 24/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0078 - val_loss: 0.0093\n",
      "Epoch 25/25\n",
      "60/60 [==============================] - 10s 165ms/step - loss: 0.0092 - val_loss: 0.0098\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g_n2VfMsg1NT",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "e20fc8d4-968c-4272-9c62-57eeefcee1b3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.evaluate(test_x,test_y)"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0098\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.009824990294873714"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oNuY-45SngR",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VTfYjsyJTEtv",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# create some sample data\n",
    "X, Y = convert(x_test, y_test)"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QPazH1zFTnE4",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "535d81f5-7835-47ce-98a0-6d78bfe13c78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# get prediction for one sample\n",
    "y_pred = model.predict(X)\n",
    "y_pred.shape"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 3150, 15)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jrD03dgjcZMO",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "OBJperCLASS = 10  # get the top 10 results for each class\n",
    "\n",
    "\n",
    "# get the confidence scores (with class values) and delta for the boxes. For each class, the top 10 values are used\n",
    "def infer(Y):\n",
    "  # classes are actually the index into the default boxes\n",
    "  classes = np.zeros((OBJperCLASS, outputChannels-4), dtype=np.uint16)\n",
    "  conf = np.zeros((OBJperCLASS, outputChannels-4))\n",
    "  delta = np.zeros((OBJperCLASS, outputChannels-4, 4))\n",
    "  class_predictions = softmax(Y[:, :outputChannels-4], axis=1)\n",
    "  for i in range(outputChannels-4):\n",
    "    classes[:, i] = bottleneck.argpartition(class_predictions[:, i], BOXES-1-10, axis=-1)[-OBJperCLASS:]\n",
    "    conf[:, i] = class_predictions[classes[:, i], i]\n",
    "    delta[:, i] = Y[classes[:, i], outputChannels-4:]\n",
    "  return conf, classes, delta\n",
    "\n",
    "\n",
    "# generate bounding boxes from the inferred outputs\n",
    "def Bbox(confidence, box_idx, delta):\n",
    "  #delta contains delta(cx,cy,h,w)\n",
    "  bbox_centre = np.zeros((OBJperCLASS, outputChannels-4, 2))\n",
    "  bbox_hw = np.zeros((OBJperCLASS, outputChannels-4, 2))\n",
    "  for i in range(OBJperCLASS):\n",
    "    bbox_centre[i, :, 0] = centres[box_idx[i]][:, 0]+delta[i, :, 0]\n",
    "    bbox_centre[i, :, 1] = centres[box_idx[i]][:, 1]+delta[i, :, 1]\n",
    "    bbox_hw[i, :, 0] = hw[box_idx[i]][:, 0]+delta[i, :, 2]\n",
    "    bbox_hw[i, :, 1] = hw[box_idx[i]][:, 1]+delta[i, :, 3]\n",
    "  return bbox_centre, bbox_hw"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LY7SOlpafX51",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "outputId": "eef5e296-27f6-46f1-bfeb-422573f1d1e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "r = np.random.randint(TESTSIZE)\n",
    "\n",
    "# top 10 predictions for each class\n",
    "confidence, box_idx, delta = infer(y_pred[r])\n",
    "bbox_centre, bbox_hw = Bbox(confidence, box_idx, delta)\n",
    "\n",
    "im = np.array(Image.fromarray(X[r].astype(np.uint8)))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(im)\n",
    "\n",
    "for i in range(outputChannels-4):\n",
    "  # skipping backgrounds\n",
    "  if i == NUM_CLASSES:\n",
    "    continue\n",
    "  color = 'r'\n",
    "  # if a class is mentioned in the ground truth, color the boxes green\n",
    "  if i in Y[r, :, 0]:\n",
    "    color = 'g'\n",
    "    print(i)\n",
    "\n",
    "  # skip all the classes which have low confidence values\n",
    "  if (confidence[:, i] > 0.5).any() or i in Y[r, :, 0]:\n",
    "    for k in range(OBJperCLASS):\n",
    "      print(\n",
    "        \"{}: Confidence-{}\\t\\tCentre-{} Height,Width-{}\".format(i, confidence[k, i], bbox_centre[k, i], bbox_hw[k, i]))\n",
    "\n",
    "      # draw bounding box only if confidence scores are high\n",
    "      if confidence[k, i] < 0.5:\n",
    "        continue\n",
    "      x = bbox_centre[k, i, 0]-bbox_hw[k, i, 0]/2\n",
    "      y = bbox_centre[k, i, 1]-bbox_hw[k, i, 1]/2\n",
    "      rect = patches.Rectangle((y, x), bbox_hw[k, i, 1], bbox_hw[k, i, 0], linewidth=1, edgecolor=color,\n",
    "                               facecolor='none')\n",
    "      ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "7\n",
      "7: Confidence-0.7365235686302185\t\tCentre-[42.19794345 98.16143656] Height,Width-[32.29747125 32.31169936]\n",
      "7: Confidence-0.8857401013374329\t\tCentre-[31.7246573  91.92364167] Height,Width-[38.88492426 28.39619501]\n",
      "7: Confidence-0.9466167688369751\t\tCentre-[37.35820007 95.4094162 ] Height,Width-[28.65339181 29.04177281]\n",
      "7: Confidence-0.9956559538841248\t\tCentre-[37.51727843 93.68477857] Height,Width-[27.14049515 28.02397426]\n",
      "7: Confidence-0.9956580996513367\t\tCentre-[36.07167462 96.26651478] Height,Width-[27.35519641 40.82926547]\n",
      "7: Confidence-0.9860585927963257\t\tCentre-[36.14206849 88.0132165 ] Height,Width-[26.96784037 42.68980633]\n",
      "7: Confidence-0.9980512857437134\t\tCentre-[35.96905352 92.87503022] Height,Width-[27.35304659 40.9342879 ]\n",
      "7: Confidence-0.9995020627975464\t\tCentre-[39.372262   93.71296859] Height,Width-[28.78150412 28.83308884]\n",
      "7: Confidence-0.9984629154205322\t\tCentre-[38.21918631 94.18664432] Height,Width-[27.11899134 27.2651076 ]\n",
      "7: Confidence-0.9972821474075317\t\tCentre-[37.71326017 92.93149531] Height,Width-[29.38378605 28.26766874]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z32HPrzihVqN",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": 34,
   "outputs": []
  }
 ]
}