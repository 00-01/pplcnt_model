{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Mobilenetv2 + SSD.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "_hvSY3X-AeFP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "1039d725-6ddc-4032-f23c-a33ccd056bc8"
   },
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy.matlib\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# import Bottleneck"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFmrlFJ8uKCe",
    "colab_type": "text"
   },
   "source": [
    "## MODEL\n",
    "Define Bottleneck Residual layer for MobileNet using the same parameters as mentioned in the paper"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xmwhyyS7CFyK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class Bottleneck(tf.keras.Model):\n",
    "  def __init__(self, expansion, filters, stride, block_id, alpha=1, ):\n",
    "    super(Bottleneck, self).__init__(name=\"Bottleneck_\"+block_id)\n",
    "    self.expansion = expansion\n",
    "    self.alpha = alpha\n",
    "    self.output_channels = self.alpha*filters\n",
    "    self.stride = stride\n",
    "    self.out = None  # there was some problem with the eager execution\n",
    "\n",
    "    prefix = 'Bottleneck_{}_'.format(block_id)\n",
    "    self.prefix = prefix\n",
    "    # expansion\n",
    "    self.expand_BN = layers.BatchNormalization(name=prefix+'expand_BN')\n",
    "    self.expand_ReLU = layers.ReLU(max_value=6, name=prefix+'expand_ReLU')\n",
    "    # conv\n",
    "    self.Conv = layers.DepthwiseConv2D(kernel_size=3, padding='same', strides=self.stride, use_bias=False, name=prefix+'conv')\n",
    "    self.Conv_BN = layers.BatchNormalization(name=prefix+'conv_BN')\n",
    "    self.Conv_ReLU = layers.ReLU(max_value=6, name=prefix+'conv_ReLU')\n",
    "    # project\n",
    "    self.project = layers.Conv2D(filters=self.output_channels, kernel_size=1, use_bias=False, name='contract')\n",
    "    self.project_BN = layers.BatchNormalization(name=prefix+'contract_BN')\n",
    "    # dimensions need to be the same for residual connection\n",
    "    self.residual = layers.Add(name=prefix+'residual')\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.d = input_shape[-1]\n",
    "    self.expand = layers.Conv2D(filters=self.expansion*self.d, kernel_size=1, use_bias=False, name=self.prefix+'expand')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.expand(inputs)\n",
    "    x = self.expand_BN(x)\n",
    "    x = self.expand_ReLU(x)\n",
    "    self.out = x\n",
    "\n",
    "    x = self.Conv(x)\n",
    "    x = self.Conv_BN(x)\n",
    "    x = self.Conv_ReLU(x)\n",
    "\n",
    "    x = self.project(x)\n",
    "    x = self.project_BN(x)\n",
    "\n",
    "    if self.output_channels == self.d and self.stride == 1:\n",
    "      x = self.residual([inputs, x])\n",
    "\n",
    "    return x\n",
    "\n",
    "  def model(self):\n",
    "    x = tf.keras.Input(shape=(80, 80, 1))\n",
    "    return tf.keras.Model(inputs=[x], outputs=self.call(x))"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VYGagWE8T2Et",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class MobileNetv2(tf.keras.Model):\n",
    "  def __init__(self, k=11):\n",
    "    super(MobileNetv2, self).__init__()\n",
    "    self.k = k\n",
    "\n",
    "    # self.pad = layers.ZeroPadding2D(padding=2, name='pad')\n",
    "    self.conv_inp = layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "    self.BN = layers.BatchNormalization(name='BN')\n",
    "    self.ReLU = layers.ReLU(max_value=6, name='ReLU')\n",
    "\n",
    "    self.B1_1 = Bottleneck(expansion=1, filters=16, stride=1, block_id='B1_1')\n",
    "\n",
    "    self.B2_1 = Bottleneck(expansion=6, filters=24, stride=2, block_id='B2_1')\n",
    "    self.B2_2 = Bottleneck(expansion=6, filters=24, stride=1, block_id='B2_2')\n",
    "\n",
    "    self.B3_1 = Bottleneck(expansion=6, filters=32, stride=2, block_id='B3_1')\n",
    "    self.B3_2 = Bottleneck(expansion=6, filters=32, stride=1, block_id='B3_2')\n",
    "    self.B3_3 = Bottleneck(expansion=6, filters=32, stride=1, block_id='B3_3')\n",
    "\n",
    "    self.B4_1 = Bottleneck(expansion=6, filters=64, stride=2, block_id='B4_1')\n",
    "    self.B4_2 = Bottleneck(expansion=6, filters=64, stride=1, block_id='B4_2')\n",
    "    self.B4_3 = Bottleneck(expansion=6, filters=64, stride=1, block_id='B4_3')\n",
    "    self.B4_4 = Bottleneck(expansion=6, filters=64, stride=1, block_id='B4_4')\n",
    "\n",
    "    self.B5_1 = Bottleneck(expansion=6, filters=96, stride=1, block_id='B5_1')\n",
    "    self.B5_2 = Bottleneck(expansion=6, filters=96, stride=1, block_id='B5_2')\n",
    "    self.B5_3 = Bottleneck(expansion=6, filters=96, stride=1, block_id='B5_3')\n",
    "\n",
    "    self.B6_1 = Bottleneck(expansion=6, filters=160, stride=2, block_id='B6_1')\n",
    "    self.B6_2 = Bottleneck(expansion=6, filters=160, stride=1, block_id='B6_2')\n",
    "    self.B6_3 = Bottleneck(expansion=6, filters=160, stride=1, block_id='B6_3')\n",
    "\n",
    "    self.B7_1 = Bottleneck(expansion=6, filters=320, stride=1, block_id='B7_1')\n",
    "\n",
    "    self.conv_out = layers.Conv2D(filters=1280, kernel_size=1, strides=(1, 1), use_bias=False, name='conv_out')\n",
    "    self.avgpool = layers.AveragePooling2D(pool_size=(3, 3), name='avg_pool')\n",
    "    self.conv_seg = layers.Conv2D(filters=self.k, kernel_size=1, strides=(1, 1), use_bias=False, name='conv_seg')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.conv_inp(inputs)\n",
    "    # x = self.BN(x)\n",
    "    # x = self.ReLU(x)\n",
    "\n",
    "    x = self.B1_1(x)\n",
    "\n",
    "    x = self.B2_1(x)\n",
    "    x = self.B2_2(x)\n",
    "\n",
    "    x = self.B3_1(x)\n",
    "    x = self.B3_2(x)\n",
    "    x = self.B3_3(x)\n",
    "\n",
    "    x = self.B4_1(x)\n",
    "    x = self.B4_2(x)\n",
    "    x = self.B4_3(x)\n",
    "    x = self.B4_4(x)\n",
    "\n",
    "    x = self.B5_1(x)\n",
    "    x = self.B5_2(x)\n",
    "    x = self.B5_3(x)\n",
    "\n",
    "    x = self.B6_1(x)\n",
    "    x = self.B6_2(x)\n",
    "    x = self.B6_3(x)\n",
    "\n",
    "    x = self.B7_1(x)\n",
    "\n",
    "    x = self.conv_out(x)\n",
    "    x = self.avgpool(x)\n",
    "    c4 = self.conv_seg(x)\n",
    "\n",
    "    return c4\n",
    "\n",
    "  def model(self):\n",
    "    x = tf.keras.Input(shape=(80, 80, 1))\n",
    "\n",
    "    return tf.keras.Model(inputs=x, outputs=self.call(x))"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "05i7363EYwmP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "outputId": "d8434d3b-e85a-4481-b5bd-15751d6e9140"
   },
   "source": [
    "# MOBILENET\n",
    "MobileNetv2().model().summary()"
   ],
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 80, 80, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 40, 40, 32)        320       \n",
      "                                                                 \n",
      " Bottleneck_B1_1 (Bottleneck  (None, 40, 40, 16)       2144      \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B2_1 (Bottleneck  (None, 20, 20, 24)       5568      \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B2_2 (Bottleneck  (None, 20, 20, 24)       9456      \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B3_1 (Bottleneck  (None, 10, 10, 32)       10640     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B3_2 (Bottleneck  (None, 10, 10, 32)       15680     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B3_3 (Bottleneck  (None, 10, 10, 32)       15680     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B4_1 (Bottleneck  (None, 5, 5, 64)         21952     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B4_2 (Bottleneck  (None, 5, 5, 64)         55936     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B4_3 (Bottleneck  (None, 5, 5, 64)         55936     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B4_4 (Bottleneck  (None, 5, 5, 64)         55936     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B5_1 (Bottleneck  (None, 5, 5, 96)         68352     \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B5_2 (Bottleneck  (None, 5, 5, 96)         120768    \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B5_3 (Bottleneck  (None, 5, 5, 96)         120768    \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B6_1 (Bottleneck  (None, 3, 3, 160)        157888    \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B6_2 (Bottleneck  (None, 3, 3, 160)        324160    \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B6_3 (Bottleneck  (None, 3, 3, 160)        324160    \n",
      " )                                                               \n",
      "                                                                 \n",
      " Bottleneck_B7_1 (Bottleneck  (None, 3, 3, 320)        478400    \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_out (Conv2D)           (None, 3, 3, 1280)        409600    \n",
      "                                                                 \n",
      " avg_pool (AveragePooling2D)  (None, 1, 1, 1280)       0         \n",
      "                                                                 \n",
      " conv_seg (Conv2D)           (None, 1, 1, 11)          14080     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,267,424\n",
      "Trainable params: 2,235,872\n",
      "Non-trainable params: 31,552\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class SSD(tf.keras.Model):\n",
    "  def __init__(self, numBoxes=[4, 6, 6, 6, 4, 4], layerWidth=[28, 14, 7, 4, 2, 1], k=10+1+4):\n",
    "    super(SSD, self).__init__()\n",
    "    self.classes = k\n",
    "    self.featureMaps = 6\n",
    "    self.MobileNet = MobileNetv2(k=k)\n",
    "    self.numBoxes = numBoxes\n",
    "    self.layerWidth = layerWidth\n",
    "    self.features = [None for _ in range(self.featureMaps)]\n",
    "    self.classifiers = [None for _ in range(self.featureMaps)]\n",
    "\n",
    "    self.conv1_1 = layers.Conv2D(256, 1, name='SSD_conv_1_1')\n",
    "    self.conv1_2 = layers.Conv2D(512, 3, strides=(2, 2), padding='same', name='SSD_conv_1_2')\n",
    "\n",
    "    self.conv2_1 = layers.Conv2D(128, 1, name='SSD_conv_2_1')\n",
    "    self.conv2_2 = layers.Conv2D(256, 3, strides=(2, 2), padding='same', name='SSD_conv_2_2')\n",
    "\n",
    "    self.conv3_1 = layers.Conv2D(128, 1, name='SSD_conv_3_1')\n",
    "    self.conv3_2 = layers.Conv2D(256, 3, strides=(1, 1), name='SSD_conv_3_2')\n",
    "\n",
    "    self.conv4_1 = layers.Conv2D(128, 1, name='SSD_conv_4_1')\n",
    "    self.conv4_2 = layers.Conv2D(256, 2, strides=(1, 1), name='SSD_conv_4_2')  # changed kernel size to 2 since output of previous layer has width 3\n",
    "    self.conv = []\n",
    "    self.reshape = []\n",
    "\n",
    "    for i in range(self.featureMaps):\n",
    "      self.conv.append(layers.Conv2D(self.numBoxes[i]*self.classes, 3, padding='same', name='Classification_'+str(i)))\n",
    "      self.reshape.append(layers.Reshape((self.layerWidth[i]*self.layerWidth[i]*self.numBoxes[i], self.classes), name='Reshape_classification_'+str(i)))\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.MobileNet.build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = inputs\n",
    "    x = self.MobileNet(x)\n",
    "\n",
    "    # get the convolved images at different resolutions\n",
    "    self.features[0] = self.MobileNet.get_layer('Bottleneck_B4_1').out\n",
    "    self.features[1] = self.MobileNet.get_layer('Bottleneck_B5_3').out\n",
    "    self.features[2] = self.conv1_2(self.conv1_1(self.features[1]))\n",
    "    self.features[3] = self.conv2_2(self.conv2_1(self.features[2]))\n",
    "    self.features[4] = self.conv3_2(self.conv3_1(self.features[3]))\n",
    "    self.features[5] = self.conv4_2(self.conv4_1(self.features[4]))\n",
    "\n",
    "    for i in range(self.featureMaps):\n",
    "      # for each feature map, create predictions according to the number of boxes for that layer and the number of output channels\n",
    "      x = self.conv[i](self.features[i])\n",
    "      x = self.reshape[i](x)\n",
    "      self.classifiers[i] = x\n",
    "\n",
    "    # concatenate all the classifiers\n",
    "    x = layers.concatenate(self.classifiers, axis=-2, name='concatenate')\n",
    "    return x\n",
    "\n",
    "  def model(self):\n",
    "    x = tf.keras.Input(shape=(80, 80, 1))\n",
    "    return tf.keras.Model(inputs=x, outputs=self.call(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "29A_FW-GxK4t",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# # SSD\n",
    "# NUM_CLASSES = 1\n",
    "# # first 2 dimensions should be equal to width of output from bottleneck expand ReLU at the (4,1) and (5,3) respectively.\n",
    "# # dimensions after second one are determined by convolutions written inside SSD (conv1_2, conv2_2, conv3_3, conv4_2)\n",
    "# layerWidths = [28, 14, 7, 4, 2, 1]\n",
    "# numBoxes = [3, 3, 3, 3, 3, 3]\n",
    "# assert len(numBoxes) == len(layerWidths)  # numBoxes for each layer and each layer has a specific width\n",
    "# outputChannels = NUM_CLASSES+1+4  # 1 classes + background + cx,cy,h,w\n",
    "# assert outputChannels-NUM_CLASSES == 5\n",
    "\n",
    "model = SSD(numBoxes=[3, 3, 3, 3, 3, 3], layerWidth=[28, 14, 7, 4, 2, 1], k=1+4)\n",
    "model.model().summary()"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"SSD_conv_1_1\" (type Conv2D).\n\nOriginated from a graph execution error.\n\nThe graph execution error is detected at a node built at (most recent call last):\n>>>  File /usr/lib/python3.8/runpy.py, line 194, in _run_module_as_main\n>>>  File /usr/lib/python3.8/runpy.py, line 87, in _run_code\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel_launcher.py, line 16, in <module>\n>>>  File /home/z/.local/lib/python3.8/site-packages/traitlets/config/application.py, line 846, in launch_instance\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py, line 677, in start\n>>>  File /home/z/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py, line 199, in start\n>>>  File /usr/lib/python3.8/asyncio/base_events.py, line 570, in run_forever\n>>>  File /usr/lib/python3.8/asyncio/base_events.py, line 1859, in _run_once\n>>>  File /usr/lib/python3.8/asyncio/events.py, line 81, in _run\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 457, in dispatch_queue\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 446, in process_one\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 353, in dispatch_shell\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 648, in execute_request\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py, line 353, in do_execute\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py, line 533, in run_cell\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 2914, in run_cell\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 2960, in _run_cell\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py, line 78, in _pseudo_sync_runner\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 3185, in run_cell_async\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 3377, in run_ast_nodes\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 3457, in run_code\n>>>  File /tmp/ipykernel_23453/3554172567.py, line 12, in <module>\n>>>  File /tmp/ipykernel_23453/359622308.py, line 57, in model\n>>>  File /tmp/ipykernel_23453/359622308.py, line 35, in call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 64, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1032, in __call__\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1173, in _functional_construction_call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 897, in _keras_tensor_symbolic_call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 942, in _infer_output_signature\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 92, in error_handler\n>>>  File /tmp/ipykernel_23453/483620674.py, line 60, in call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 64, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1096, in __call__\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 92, in error_handler\n>>>  File /tmp/ipykernel_23453/3649786816.py, line 32, in call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 64, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1096, in __call__\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 92, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/layers/advanced_activations.py, line 433, in call\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py, line 150, in error_handler\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py, line 1096, in op_dispatch_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/backend.py, line 4953, in relu\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py, line 150, in error_handler\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py, line 1096, in op_dispatch_handler\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py, line 3634, in relu6\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 10616, in relu6\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py, line 744, in _apply_op_helper\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py, line 689, in _create_op_internal\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py, line 3697, in _create_op_internal\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py, line 2101, in __init__\n\nError detected in node 'mobile_netv2_9/Bottleneck_B5_3/Bottleneck_B5_3_expand_ReLU/Relu6' defined at: File \"/usr/local/lib/python3.8/dist-packages/keras/backend.py\", line 4953, in relu\n\nTypeError: tf.Graph captured an external symbolic tensor. The symbolic tensor 'mobile_netv2_9/Bottleneck_B5_3/Bottleneck_B5_3_expand_ReLU/Relu6:0' created by node 'mobile_netv2_9/Bottleneck_B5_3/Bottleneck_B5_3_expand_ReLU/Relu6' is captured by the tf.Graph being executed as an input. But a tf.Graph is not allowed to take symbolic tensors from another graph as its inputs. Make sure all captured inputs of the executing tf.Graph are not symbolic tensors. Use return values, explicit Python locals or TensorFlow collections to access it. Please see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 5, 5, 576), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_23453/3554172567.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSSD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnumBoxes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnumBoxes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayerWidth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlayerWidths\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutputChannels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_23453/359622308.py\u001B[0m in \u001B[0;36mmodel\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mInput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m80\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m80\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 57\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_23453/359622308.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMobileNet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Bottleneck_B4_1'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMobileNet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Bottleneck_B5_3'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1_2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1_1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2_2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2_1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv3_2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv3_1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     60\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Exception encountered when calling layer \"SSD_conv_1_1\" (type Conv2D).\n\nOriginated from a graph execution error.\n\nThe graph execution error is detected at a node built at (most recent call last):\n>>>  File /usr/lib/python3.8/runpy.py, line 194, in _run_module_as_main\n>>>  File /usr/lib/python3.8/runpy.py, line 87, in _run_code\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel_launcher.py, line 16, in <module>\n>>>  File /home/z/.local/lib/python3.8/site-packages/traitlets/config/application.py, line 846, in launch_instance\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py, line 677, in start\n>>>  File /home/z/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py, line 199, in start\n>>>  File /usr/lib/python3.8/asyncio/base_events.py, line 570, in run_forever\n>>>  File /usr/lib/python3.8/asyncio/base_events.py, line 1859, in _run_once\n>>>  File /usr/lib/python3.8/asyncio/events.py, line 81, in _run\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 457, in dispatch_queue\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 446, in process_one\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 353, in dispatch_shell\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py, line 648, in execute_request\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py, line 353, in do_execute\n>>>  File /home/z/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py, line 533, in run_cell\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 2914, in run_cell\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 2960, in _run_cell\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py, line 78, in _pseudo_sync_runner\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 3185, in run_cell_async\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 3377, in run_ast_nodes\n>>>  File /home/z/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py, line 3457, in run_code\n>>>  File /tmp/ipykernel_23453/3554172567.py, line 12, in <module>\n>>>  File /tmp/ipykernel_23453/359622308.py, line 57, in model\n>>>  File /tmp/ipykernel_23453/359622308.py, line 35, in call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 64, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1032, in __call__\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1173, in _functional_construction_call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 897, in _keras_tensor_symbolic_call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 942, in _infer_output_signature\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 92, in error_handler\n>>>  File /tmp/ipykernel_23453/483620674.py, line 60, in call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 64, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1096, in __call__\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 92, in error_handler\n>>>  File /tmp/ipykernel_23453/3649786816.py, line 32, in call\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 64, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py, line 1096, in __call__\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py, line 92, in error_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/layers/advanced_activations.py, line 433, in call\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py, line 150, in error_handler\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py, line 1096, in op_dispatch_handler\n>>>  File /usr/local/lib/python3.8/dist-packages/keras/backend.py, line 4953, in relu\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py, line 150, in error_handler\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py, line 1096, in op_dispatch_handler\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py, line 3634, in relu6\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py, line 10616, in relu6\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py, line 744, in _apply_op_helper\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py, line 689, in _create_op_internal\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py, line 3697, in _create_op_internal\n>>>  File /home/z/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py, line 2101, in __init__\n\nError detected in node 'mobile_netv2_9/Bottleneck_B5_3/Bottleneck_B5_3_expand_ReLU/Relu6' defined at: File \"/usr/local/lib/python3.8/dist-packages/keras/backend.py\", line 4953, in relu\n\nTypeError: tf.Graph captured an external symbolic tensor. The symbolic tensor 'mobile_netv2_9/Bottleneck_B5_3/Bottleneck_B5_3_expand_ReLU/Relu6:0' created by node 'mobile_netv2_9/Bottleneck_B5_3/Bottleneck_B5_3_expand_ReLU/Relu6' is captured by the tf.Graph being executed as an input. But a tf.Graph is not allowed to take symbolic tensors from another graph as its inputs. Make sure all captured inputs of the executing tf.Graph are not symbolic tensors. Use return values, explicit Python locals or TensorFlow collections to access it. Please see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 5, 5, 576), dtype=float32)"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RA7NxfQ7_G6",
    "colab_type": "text"
   },
   "source": [
    "## BOXES & IoU"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yRYi7Ez7UzpH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# I used less varying custom scales and aspect ratios here, since dataset is already uniform\n",
    "\n",
    "#IMPORTANT: before changing the scales and aspect ratios, read the comment below\n",
    "# number of scales is equal to number of different resolutions ie num of layer widths\n",
    "# for a given resolution, we have different aspect ratios\n",
    "# num(scales) = num(layerWidth) = num(numBoxes) and num(asp_ratios) = numBoxes[i]\n",
    "MinScale = .1  # Min and Max scale given as percentage\n",
    "MaxScale = 1.5\n",
    "scales = [MinScale+x/len(layerWidths)*(MaxScale-MinScale) for x in range(len(layerWidths))]\n",
    "scales = scales[::-1]  # reversing the order because the layerWidths go from high to low (lower to higher resoltuion)\n",
    "\n",
    "asp = [0.5, 1.0, 1.5]\n",
    "asp1 = [x**0.5 for x in asp]\n",
    "asp2 = [1/x for x in asp1]\n",
    "IMG_SIZE = 80\n",
    "# should be equal to the 1st dimension in the output layer of the SSD model\n",
    "BOXES = sum([a*a*b for a, b in zip(layerWidths, numBoxes)])\n",
    "centres = np.zeros((BOXES, 2))\n",
    "hw = np.zeros((BOXES, 2))\n",
    "boxes = np.zeros((BOXES, 4))\n",
    "print(BOXES)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9A1xGMrXVX18",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# calculating default box centres and height, width\n",
    "idx = 0\n",
    "for gridSize, numBox, scale in zip(layerWidths, numBoxes, scales):\n",
    "  step_size = IMG_SIZE*1.0/gridSize\n",
    "  for i in range(gridSize):\n",
    "    for j in range(gridSize):\n",
    "      pos = idx+(i*gridSize+j)*numBox\n",
    "      # centre is the same for all aspect ratios(=numBox)\n",
    "      centres[pos: pos+numBox, :] = i*step_size+step_size/2, j*step_size+step_size/2\n",
    "      # height and width vary according to the scale and aspect ratio\n",
    "      # zip asepct ratios and then scale them by the scaling factor\n",
    "      hw[pos: pos+numBox, :] = np.multiply(gridSize*scale, np.squeeze(np.dstack([asp1, asp2]), axis=0))[:numBox, :]\n",
    "  idx += gridSize*gridSize*numBox\n",
    "\n",
    "# (x,y) co-ordinates of top left and bottom right\n",
    "# This actually is not used anywhere. centres[] and hw[] are good enough substitute\n",
    "boxes[:, 0] = centres[:, 0]-hw[:, 0]/2\n",
    "boxes[:, 1] = centres[:, 1]-hw[:, 1]/2\n",
    "boxes[:, 2] = centres[:, 0]+hw[:, 0]/2\n",
    "boxes[:, 3] = centres[:, 1]+hw[:, 1]/2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TJSIPHPMh3N2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# calculate IoU for a set of search boxes and default boxes\n",
    "def IoU(box1, box2):\n",
    "  box1 = box1.astype(np.float64)\n",
    "  box2 = box2.astype(np.float64)\n",
    "  # find left and right co-ordinates of edges. Min should be less than Max for non zero overlap\n",
    "  xmin = np.maximum(box1[:, 0], box2[:, 0])\n",
    "  xmax = np.minimum(box1[:, 2], box2[:, 2])\n",
    "  ymin = np.maximum(box1[:, 1], box2[:, 1])\n",
    "  ymax = np.minimum(box1[:, 3], box2[:, 3])\n",
    "\n",
    "  intersection = np.abs(np.maximum(xmax-xmin, 0)*np.maximum(ymax-ymin, 0))\n",
    "  boxArea1 = np.abs((box1[:, 2]-box1[:, 0])*(box1[:, 3]-box1[:, 1]))\n",
    "  boxArea2 = np.abs((box2[:, 2]-box2[:, 0])*(box2[:, 3]-box2[:, 1]))\n",
    "  unionArea = boxArea1+boxArea2-intersection\n",
    "  assert (unionArea > 0).all()\n",
    "  iou = intersection/unionArea\n",
    "\n",
    "  return iou\n",
    "\n",
    "\n",
    "# give index of box correpsonding to IoUs > threshold (=0.5)\n",
    "def bestIoU(searchBox):\n",
    "  THRESHOLD = 0.5\n",
    "  return np.argwhere(IoU(numpy.matlib.repmat(searchBox, BOXES, 1), boxes) > THRESHOLD)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm2k4c5Ik_BX",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PEgx1Sdcq7yJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# take mnist x and y pairs and convert to input, output pairs for the MobileNetv2+SSD model\n",
    "def convert(x, y):\n",
    "  MNIST_SIZE = x.shape[-1]\n",
    "  # create a 2D array of top left corners for the mnist image to be placed\n",
    "  corner = np.random.randint(IMG_SIZE-MNIST_SIZE, size=(x.shape[0], 2))\n",
    "\n",
    "  # create a blank canvas for the input with the required dimension\n",
    "  input = np.zeros((x.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "  # replacing a part by RGB version of MNIST\n",
    "  for i in range(x.shape[0]):\n",
    "    lx = int(corner[i, 0])\n",
    "    ly = int(corner[i, 1])\n",
    "    input[i, lx:lx+MNIST_SIZE, ly:ly+MNIST_SIZE, :] = np.repeat(np.expand_dims(np.array(x[i, :, :]), axis=-1), 3, axis=-1)\n",
    "\n",
    "  # for each default box, there are 5 values: class number and delta cx,cy,h,w\n",
    "  output = np.zeros((y.shape[0], BOXES, 1+4))\n",
    "  output[:, :, 0] = NUM_CLASSES  # defaulting class labels for all boxes to background initially\n",
    "  for i in range(x.shape[0]):\n",
    "    bbox = np.zeros(4)\n",
    "    bbox[:2] = corner[i]\n",
    "    bbox[2:] = corner[i]+(MNIST_SIZE, MNIST_SIZE)\n",
    "    # for all default boxes which have IoU > threshold, set the delta values and class number\n",
    "    box_idx = bestIoU(bbox).astype(np.uint16)\n",
    "    output[i, box_idx, 0] = y[i]\n",
    "    output[i, box_idx, 1] = (bbox[0]+bbox[2])/2.0-centres[box_idx, 0]\n",
    "    output[i, box_idx, 2] = (bbox[1]+bbox[3])/2.0-centres[box_idx, 1]\n",
    "    output[i, box_idx, 3] = MNIST_SIZE-hw[box_idx, 0]\n",
    "    output[i, box_idx, 4] = MNIST_SIZE-hw[box_idx, 1]\n",
    "\n",
    "  return input, output\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sk_z17wV3Bj5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "TRAINSIZE = 600\n",
    "TESTSIZE = 100\n",
    "\n",
    "x_train = x_train[:TRAINSIZE, :, :]\n",
    "y_train = y_train[:TRAINSIZE]\n",
    "x_test = x_test[:TESTSIZE, :, :]\n",
    "y_test = y_test[:TESTSIZE]\n",
    "\n",
    "test_x, test_y = convert(x_test, y_test)\n",
    "train_x, train_y = convert(x_train, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NAwnJnu4qE0P",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "outputId": "27116f08-73e6-42e7-c8d8-daac27654afc"
   },
   "source": [
    "# checking if the inputs prepared are correct or not\n",
    "r = np.random.randint(0, train_x.shape[0])\n",
    "img = train_x[r, :, :, :].copy()\n",
    "img_y = train_y[r]\n",
    "\n",
    "im = np.array(Image.fromarray(img.astype(np.uint8)))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(im)\n",
    "\n",
    "# find all boxes where class label is not background\n",
    "idx = np.argwhere(img_y[:, 0] != NUM_CLASSES)[:, 0]\n",
    "print('Number of boxes with IoU > 0.5:', idx.shape[0])\n",
    "print('Green box: ground truth. Red box: default boxes with IoU > threshold')\n",
    "\n",
    "#calculating the ground truth bounding boxes\n",
    "gt = np.zeros(4, dtype=np.uint16)\n",
    "gt[:2] = (img_y[idx[0], 1:3]+centres[idx[0], :2])\n",
    "gt[2:] = (img_y[idx[0], 3:]+hw[idx[0], :])\n",
    "\n",
    "# for some reason, x and y are inverted\n",
    "rect = patches.Rectangle((gt[1]-gt[3]/2, gt[0]-gt[2]/2), gt[3], gt[2], linewidth=5, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# showing all the boxes with IoU > 0.5\n",
    "for i in idx:\n",
    "  rect = patches.Rectangle((centres[i][1]-hw[i, 1]/2, centres[i][0]-hw[i, 0]/2), hw[i, 1], hw[i, 0], linewidth=1, edgecolor='r', facecolor='none')\n",
    "  ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1nI7mXjS8zA9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "88b50f5a-8931-4f30-eb69-f211e964d690"
   },
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "\n",
    "print(train_dataset.element_spec)\n",
    "print(test_dataset.element_spec)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oyX8dnwQ8_1k",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "BATCH_SIZE = 10\n",
    "SHUFFLE_BUFFER_SIZE = 60\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LOSS FUNCTION\n",
    "Hard negative mining hasn't been done here\n",
    "Initial idea was to assign weights to background classes, but there is some problem in that approach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# label is not required here in the standard implementation\n",
    "# calculate smooth L1 loss\n",
    "def smoothL1(x, y, label):\n",
    "  diff = K.abs(x-y)  #* K.switch(label == 10, label*1.0/BOXES, label)\n",
    "  result = K.switch(diff < 1, 0.5*diff**2, diff-0.5)\n",
    "  return K.mean(result)\n",
    "\n",
    "\n",
    "def confidenceLoss(y, label):\n",
    "  unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(label, y)\n",
    "  # class_weights = tf.constant([[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0/BOXES]]*BOXES])\n",
    "  # weights = tf.reduce_sum(class_weights * y, axis = -1)\n",
    "  # weighted_loss = unweighted_loss * weights\n",
    "  return K.mean(unweighted_loss)\n",
    "\n",
    "\n",
    "def Loss(gt, y):\n",
    "  # shape of y is n * BOXES * output_channels\n",
    "  # shape of gt is n * BOXES * 5 \n",
    "  loss = 0\n",
    "  loss += smoothL1(y[:, :, -4:], gt[:, :, -4:], gt[:, :, 0:1])  # localisation loss\n",
    "  loss += confidenceLoss(y[:, :, :-4], tf.cast(gt[:, :, 0], tf.int32))  # confidence loss\n",
    "  return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRAIN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A8_O3V8DB_Gk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss=Loss)\n",
    "history = model.fit(train_dataset, epochs=2, validation_data=test_dataset)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SAVE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"pplcntr_\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model.save(filepath=model_name, overwrite=True, include_optimizer=True, save_format='tf', signatures=None, options=None, save_traces=True, )\n",
    "# model.save(model_name, save_format='tf')\n",
    "\n",
    "# ## save weight\n",
    "# model_weight = \"pplcntr_\" + dt.now().strftime(\"%Y%m%d-%H%M%S\") + \".h5\"\n",
    "# model.save_weights(model_weight, save_format='h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g_n2VfMsg1NT",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "e20fc8d4-968c-4272-9c62-57eeefcee1b3"
   },
   "source": [
    "model.evaluate(test_x, test_y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oNuY-45SngR",
    "colab_type": "text"
   },
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VTfYjsyJTEtv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# create sample data\n",
    "X, Y = convert(x_test, y_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QPazH1zFTnE4",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "535d81f5-7835-47ce-98a0-6d78bfe13c78"
   },
   "source": [
    "# get prediction for one sample\n",
    "y_pred = model.predict(X)\n",
    "print(y_pred.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jrD03dgjcZMO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "OBJperCLASS = 10  # get the top 10 results for each class\n",
    "\n",
    "\n",
    "# get the confidence scores (with class values) and delta for the boxes. For each class, the top 10 values are used\n",
    "def infer(Y):\n",
    "  # classes are actually the index into the default boxes\n",
    "  classes = np.zeros((OBJperCLASS, outputChannels-4), dtype=np.uint16)\n",
    "  conf = np.zeros((OBJperCLASS, outputChannels-4))\n",
    "  delta = np.zeros((OBJperCLASS, outputChannels-4, 4))\n",
    "  class_predictions = softmax(Y[:, :outputChannels-4], axis=1)\n",
    "  for i in range(outputChannels-4):\n",
    "    classes[:, i] = Bottleneck.argpartition(class_predictions[:, i], BOXES-1-10, axis=-1)[-OBJperCLASS:]\n",
    "    conf[:, i] = class_predictions[classes[:, i], i]\n",
    "    delta[:, i] = Y[classes[:, i], outputChannels-4:]\n",
    "\n",
    "  return conf, classes, delta\n",
    "\n",
    "\n",
    "# generate bounding boxes from the inferred outputs\n",
    "def Bbox(confidence, box_idx, delta):\n",
    "  #delta contains delta(cx,cy,h,w)\n",
    "  bbox_centre = np.zeros((OBJperCLASS, outputChannels-4, 2))\n",
    "  bbox_hw = np.zeros((OBJperCLASS, outputChannels-4, 2))\n",
    "  for i in range(OBJperCLASS):\n",
    "    bbox_centre[i, :, 0] = centres[box_idx[i]][:, 0]+delta[i, :, 0]\n",
    "    bbox_centre[i, :, 1] = centres[box_idx[i]][:, 1]+delta[i, :, 1]\n",
    "    bbox_hw[i, :, 0] = hw[box_idx[i]][:, 0]+delta[i, :, 2]\n",
    "    bbox_hw[i, :, 1] = hw[box_idx[i]][:, 1]+delta[i, :, 3]\n",
    "\n",
    "  return bbox_centre, bbox_hw"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LY7SOlpafX51",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "outputId": "eef5e296-27f6-46f1-bfeb-422573f1d1e1"
   },
   "source": [
    "r = np.random.randint(TESTSIZE)\n",
    "\n",
    "# top 10 predictions for each class\n",
    "confidence, box_idx, delta = infer(y_pred[r])\n",
    "bbox_centre, bbox_hw = Bbox(confidence, box_idx, delta)\n",
    "\n",
    "im = np.array(Image.fromarray(X[r].astype(np.uint8)))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(im)\n",
    "\n",
    "for i in range(outputChannels-4):\n",
    "  # skipping backgrounds\n",
    "  if i == NUM_CLASSES:\n",
    "    continue\n",
    "  color = 'r'\n",
    "  # if a class is mentioned in the ground truth, color the boxes green\n",
    "  if i in Y[r, :, 0]:\n",
    "    color = 'g'\n",
    "    print(i)\n",
    "\n",
    "  # skip all the classes which have low confidence values\n",
    "  if (confidence[:, i] > 0.5).any() or i in Y[r, :, 0]:\n",
    "    for k in range(OBJperCLASS):\n",
    "      print(\"{}: Confidence-{}\\t\\tCentre-{} Height,Width-{}\".format(i, confidence[k, i], bbox_centre[k, i], bbox_hw[k, i]))\n",
    "\n",
    "      # draw bounding box only if confidence scores are high\n",
    "      if confidence[k, i] < 0.5:\n",
    "        continue\n",
    "      x = bbox_centre[k, i, 0]-bbox_hw[k, i, 0]/2\n",
    "      y = bbox_centre[k, i, 1]-bbox_hw[k, i, 1]/2\n",
    "      rect = patches.Rectangle((y, x), bbox_hw[k, i, 1], bbox_hw[k, i, 0], linewidth=1, edgecolor=color, facecolor='none')\n",
    "      ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}