{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from datetime import datetime as dt\n",
    "import csv, os, glob\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. pre-process data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'light_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_22732/3448766333.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Split\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0msplit_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlight_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m0.9\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnorm_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0msplit_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msplit_index\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtrain_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0msplit_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msplit_index\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'light_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "split_index = int(len(light_data)*0.9)\n",
    "train_data, test_data = norm_data[:split_index], norm_data[split_index:]\n",
    "train_label, test_label = label_data[:split_index], label_data[split_index:]\n",
    "\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "test_label.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "print(train_data.shape, train_label.shape)\n",
    "print(test_data.shape, test_label.shape)\n",
    "\n",
    "print(train_data[100:105])\n",
    "print(train_label[100:105])\n",
    "print(test_data[100:105])\n",
    "print(test_label[100:105])"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_22732/244407831.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_label\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_label\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m105\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_label\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m105\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. make & train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "input = k.Input(shape=(80,80,1), batch_size=1)\n",
    "\n",
    "x = k.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(input)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=32, strides=(1,1), depth_multiplier=1, padding='same', activation='relu')(x)\n",
    "x = k.layers.Conv2D(filters=24, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "\n",
    "x = k.layers.Conv2D(filters=144, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(x)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=144, strides=(1,1), depth_multiplier=1, padding='same', activation='relu')(x)\n",
    "x0 = k.layers.Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "\n",
    "x = k.layers.Conv2D(filters=192, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(x0)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=192, strides=(1,1), depth_multiplier=1, padding='same', activation='relu')(x)\n",
    "x = k.layers.Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "add = k.layers.Add()([x, x0])\n",
    "\n",
    "x = k.layers.Conv2D(filters=192, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(add)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=192, strides=(1,1), depth_multiplier=1, padding='same', activation='relu')(x)\n",
    "x = k.layers.Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "add = k.layers.Add()([x, add])\n",
    "\n",
    "x0 = k.layers.Conv2D(filters=192, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(add)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=192, strides=(2,2), depth_multiplier=1, padding='same', activation='relu')(x0)\n",
    "x1 = k.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "\n",
    "x = k.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(x1)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=384, strides=(1,1), depth_multiplier=1, padding='same', activation='relu')(x)\n",
    "x = k.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "add = k.layers.Add()([x, x1])\n",
    "\n",
    "x = k.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(add)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=384, strides=(1,1), depth_multiplier=1, padding='same', activation='relu')(x)\n",
    "x = k.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "add = k.layers.Add()([x, add])\n",
    "\n",
    "x = k.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(add)\n",
    "x = k.layers.DepthwiseConv2D(kernel_size=384, strides=(1,1), depth_multiplier=1, padding='same', activation='relu')(x)\n",
    "x = k.layers.Conv2D(filters=96, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "x1 = k.layers.Conv2D(filters=576, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(x)\n",
    "\n",
    "x = k.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(x1)\n",
    "x2 = k.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(x)\n",
    "x = k.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), padding='same', activation='relu')(x2)\n",
    "x3 = k.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(x)\n",
    "\n",
    "l1 = k.layers.Conv2D(filters=12, kernel_size=(1,1), strides=(1,1), padding='same')(x0)\n",
    "l11 = k.layers.Reshape((4800,1,4))(l1)\n",
    "l2 = k.layers.Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), padding='same')(x1)\n",
    "l22 = k.layers.Reshape((3200,1,4))(l2)\n",
    "l3 = k.layers.Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), padding='same')(x2)\n",
    "l33 = k.layers.Reshape((800,1,4))(l3)\n",
    "l4 = k.layers.Conv2D(filters=32, kernel_size=(1,1), strides=(1,1), padding='same')(x3)\n",
    "l44 = k.layers.Reshape((200,1,4))(l4)\n",
    "\n",
    "y = k.layers.Concatenate(axis=1)([l11,l22,l33,l44])\n",
    "a = k.layers.Reshape((9000,4))(y)\n",
    "\n",
    "l5 = k.layers.Conv2D(filters=6, kernel_size=(1,1), strides=(1,1), padding='same')(x0)\n",
    "l55 = k.layers.Reshape((4800,2))(l5)\n",
    "l6 = k.layers.Conv2D(filters=16, kernel_size=(1,1), strides=(1,1), padding='same')(x1)\n",
    "l66 = k.layers.Reshape((3200,2))(l6)\n",
    "l7 = k.layers.Conv2D(filters=16, kernel_size=(1,1), strides=(1,1), padding='same')(x2)\n",
    "l77 = k.layers.Reshape((800,2))(l7)\n",
    "l8 = k.layers.Conv2D(filters=16, kernel_size=(1,1), strides=(1,1), padding='same')(x3)\n",
    "l88 = k.layers.Reshape((200,2))(l8)\n",
    "\n",
    "y0 = k.layers.Concatenate(axis=1)([l55,l66,l77,l88])\n",
    "r = k.activations.sigmoid(y0)\n",
    "\n",
    "\n",
    "aa = tf.\n",
    "\n",
    "\n",
    "\n",
    "output = k.layers.Concatenate()([a, r])\n",
    "\n",
    "model = k.Model(input, output)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 17:30:15.659476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-09 17:30:15.659634: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.659695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.659849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.659903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.659951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.660002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.660050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.660100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/GWT/gap_sdk/install/workstation/lib\n",
      "2022-02-09 17:30:15.660107: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-09 17:30:15.660295: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(1, 80, 80, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (1, 40, 40, 32)      320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseConv (1, 40, 40, 32)      32800       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (1, 40, 40, 24)      792         depthwise_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (1, 40, 40, 144)     3600        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (1, 40, 40, 144)     2986128     conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (1, 40, 40, 32)      4640        depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (1, 40, 40, 192)     6336        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (1, 40, 40, 192)     7078080     conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (1, 40, 40, 32)      6176        depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (1, 40, 40, 32)      0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (1, 40, 40, 192)     6336        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (1, 40, 40, 192)     7078080     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (1, 40, 40, 32)      6176        depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (1, 40, 40, 32)      0           conv2d_7[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (1, 40, 40, 192)     6336        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (1, 20, 20, 192)     7078080     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (1, 20, 20, 64)      12352       depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (1, 20, 20, 384)     24960       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (1, 20, 20, 384)     56623488    conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (1, 20, 20, 64)      24640       depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (1, 20, 20, 64)      0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (1, 20, 20, 384)     24960       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (1, 20, 20, 384)     56623488    conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (1, 20, 20, 64)      24640       depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (1, 20, 20, 64)      0           conv2d_13[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (1, 20, 20, 384)     24960       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_7 (DepthwiseCo (1, 20, 20, 384)     56623488    conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (1, 20, 20, 96)      36960       depthwise_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (1, 20, 20, 576)     55872       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (1, 20, 20, 128)     73856       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (1, 10, 10, 256)     295168      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (1, 10, 10, 128)     32896       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (1, 5, 5, 256)       295168      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (1, 40, 40, 12)      2316        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (1, 20, 20, 32)      18464       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (1, 10, 10, 32)      8224        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (1, 5, 5, 32)        8224        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (1, 40, 40, 6)       1158        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (1, 20, 20, 16)      9232        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (1, 10, 10, 16)      4112        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (1, 5, 5, 16)        4112        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (1, 4800, 1, 4)      0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (1, 3200, 1, 4)      0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (1, 800, 1, 4)       0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (1, 200, 1, 4)       0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (1, 4800, 2)         0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (1, 3200, 2)         0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (1, 800, 2)          0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (1, 200, 2)          0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (1, 9000, 1, 4)      0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (1, 9000, 2)         0           reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (1, 9000, 4)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (1, 9000, 2)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (1, 9000, 6)         0           reshape_4[0][0]                  \n",
      "                                                                 tf.math.sigmoid[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 195,146,618\n",
      "Trainable params: 195,146,618\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# load tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# fit\n",
    "log_path = \"logs/\" + dt.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = k.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=10, mode=\"auto\", verbose=2)\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, batch_size=6, epochs=1000, verbose=1, callbacks=[es]) # callbacks=[es, tensorboard_callback])\n",
    "print(history)\n",
    "\n",
    "# plot\n",
    "pd.DataFrame(history.history).plot(figsize=(16,10), grid=1, xlabel=\"epoch\", ylabel=\"accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "## save model\n",
    "model_name = \"pplcntr_\" + dt.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model.save(model_name, save_format='h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. evaluate & predict model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evauate model\n",
    "# model_name = \"/home/z/PycharmProjects/light_onoff_detector/model/light_detector_20210811-135021.h5\"\n",
    "model = k.models.load_model(model_name)\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "# print(f'test_loss: {loss} test_accuracy: {acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # launch tensorboard @ localhost:6006\n",
    "# %tensorboard --logdir logs/ --host localhost --port 6006"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.api'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_43451/3847002243.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtypes_pb2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msaver_pb2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mexporter\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgraph_rewriter_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodel_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/object_detection/exporter.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfreeze_graph\u001B[0m  \u001B[0;31m# pylint: disable=g-direct-tensorflow-import\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgraph_rewriter_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodel_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mstandard_fields\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfields\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_decoders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtf_example_decoder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/object_detection/builders/model_builder.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0manchor_generator_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbox_coder_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbox_predictor_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mhyperparams_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilders\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mimage_resizer_builder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/object_detection/builders/box_predictor_builder.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcollections\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictors\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconvolutional_box_predictor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictors\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconvolutional_keras_box_predictor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictors\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmask_rcnn_box_predictor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/object_detection/predictors/convolutional_box_predictor.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtf_slim\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mslim\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbox_predictor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mshape_utils\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mobject_detection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mstatic_shape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/object_detection/core/box_predictor.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 137\u001B[0;31m \u001B[0;32mclass\u001B[0m \u001B[0mKerasBoxPredictor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLayer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    138\u001B[0m   \u001B[0;34m\"\"\"Keras-based BoxPredictor.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__getattr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 62\u001B[0;31m     \u001B[0mmodule\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     63\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py\u001B[0m in \u001B[0;36m_load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m     \u001B[0;31m# Import the target module and insert it into the parent's namespace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m     \u001B[0mmodule\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     46\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent_module_globals\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_local_name\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/importlib/__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'keras.api'"
     ]
    }
   ],
   "source": [
    "\"\"\"Exports an SSD detection model to use with tf-lite. See export_tflite_ssd_graph.py for usage.\"\"\"\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.core.framework import attr_value_pb2\n",
    "from tensorflow.core.framework import types_pb2\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "from object_detection import exporter\n",
    "from object_detection.builders import graph_rewriter_builder\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.builders import post_processing_builder\n",
    "from object_detection.core import box_list\n",
    "from object_detection.utils import tf_version\n",
    "\n",
    "_DEFAULT_NUM_CHANNELS = 3\n",
    "_DEFAULT_NUM_COORD_BOX = 4\n",
    "\n",
    "if tf_version.is_tf1():\n",
    "    from tensorflow.tools.graph_transforms import TransformGraph  # pylint: disable=g-import-not-at-top\n",
    "\n",
    "\n",
    "def get_const_center_size_encoded_anchors(anchors):\n",
    "    \"\"\"Exports center-size encoded anchors as a constant tensor.\n",
    "    Args:\n",
    "      anchors: a float32 tensor of shape [num_anchors, 4] containing the anchor\n",
    "        boxes\n",
    "    Returns:\n",
    "      encoded_anchors: a float32 constant tensor of shape [num_anchors, 4]\n",
    "      containing the anchor boxes.\n",
    "    \"\"\"\n",
    "    anchor_boxlist = box_list.BoxList(anchors)\n",
    "    y, x, h, w = anchor_boxlist.get_center_coordinates_and_sizes()\n",
    "    num_anchors = y.get_shape().as_list()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        y_out, x_out, h_out, w_out = sess.run([y, x, h, w])\n",
    "    encoded_anchors = tf.constant(np.transpose(np.stack((y_out, x_out, h_out, w_out))), dtype=tf.float32, shape=[num_anchors[0], _DEFAULT_NUM_COORD_BOX], name='anchors')\n",
    "    return encoded_anchors\n",
    "\n",
    "\n",
    "def append_postprocessing_op(frozen_graph_def,\n",
    "                             max_detections,\n",
    "                             max_classes_per_detection,\n",
    "                             nms_score_threshold,\n",
    "                             nms_iou_threshold,\n",
    "                             num_classes,\n",
    "                             scale_values,\n",
    "                             detections_per_class=100,\n",
    "                             use_regular_nms=False,\n",
    "                             additional_output_tensors=()):\n",
    "  \"\"\"Appends postprocessing custom op.\n",
    "  Args:\n",
    "    frozen_graph_def: Frozen GraphDef for SSD model after freezing the\n",
    "      checkpoint\n",
    "    max_detections: Maximum number of detections (boxes) to show\n",
    "    max_classes_per_detection: Number of classes to display per detection\n",
    "    nms_score_threshold: Score threshold used in Non-maximal suppression in\n",
    "      post-processing\n",
    "    nms_iou_threshold: Intersection-over-union threshold used in Non-maximal\n",
    "      suppression in post-processing\n",
    "    num_classes: number of classes in SSD detector\n",
    "    scale_values: scale values is a dict with following key-value pairs\n",
    "      {y_scale: 10, x_scale: 10, h_scale: 5, w_scale: 5} that are used in decode\n",
    "        centersize boxes\n",
    "    detections_per_class: In regular NonMaxSuppression, number of anchors used\n",
    "      for NonMaxSuppression per class\n",
    "    use_regular_nms: Flag to set postprocessing op to use Regular NMS instead of\n",
    "      Fast NMS.\n",
    "    additional_output_tensors: Array of additional tensor names to output.\n",
    "      Tensors are appended after postprocessing output.\n",
    "  Returns:\n",
    "    transformed_graph_def: Frozen GraphDef with postprocessing custom op\n",
    "    appended\n",
    "    TFLite_Detection_PostProcess custom op node has four outputs:\n",
    "    detection_boxes: a float32 tensor of shape [1, num_boxes, 4] with box\n",
    "    locations\n",
    "    detection_classes: a float32 tensor of shape [1, num_boxes]\n",
    "    with class indices\n",
    "    detection_scores: a float32 tensor of shape [1, num_boxes]\n",
    "    with class scores\n",
    "    num_boxes: a float32 tensor of size 1 containing the number of detected\n",
    "    boxes\n",
    "  \"\"\"\n",
    "  new_output = frozen_graph_def.node.add()\n",
    "  new_output.op = 'TFLite_Detection_PostProcess'\n",
    "  new_output.name = 'TFLite_Detection_PostProcess'\n",
    "  new_output.attr['_output_quantized'].CopyFrom(attr_value_pb2.AttrValue(b=True))\n",
    "  new_output.attr['_output_types'].list.type.extend([types_pb2.DT_FLOAT, types_pb2.DT_FLOAT, types_pb2.DT_FLOAT, types_pb2.DT_FLOAT])\n",
    "  new_output.attr['_support_output_type_float_in_quantized_op'].CopyFrom(attr_value_pb2.AttrValue(b=True))\n",
    "  new_output.attr['max_detections'].CopyFrom(attr_value_pb2.AttrValue(i=max_detections))\n",
    "  new_output.attr['max_classes_per_detection'].CopyFrom(attr_value_pb2.AttrValue(i=max_classes_per_detection))\n",
    "  new_output.attr['nms_score_threshold'].CopyFrom(attr_value_pb2.AttrValue(f=nms_score_threshold.pop()))\n",
    "  new_output.attr['nms_iou_threshold'].CopyFrom(attr_value_pb2.AttrValue(f=nms_iou_threshold.pop()))\n",
    "  new_output.attr['num_classes'].CopyFrom(attr_value_pb2.AttrValue(i=num_classes))\n",
    "  new_output.attr['y_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['y_scale'].pop()))\n",
    "  new_output.attr['x_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['x_scale'].pop()))\n",
    "  new_output.attr['h_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['h_scale'].pop()))\n",
    "  new_output.attr['w_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['w_scale'].pop()))\n",
    "  new_output.attr['detections_per_class'].CopyFrom(attr_value_pb2.AttrValue(i=detections_per_class))\n",
    "  new_output.attr['use_regular_nms'].CopyFrom(attr_value_pb2.AttrValue(b=use_regular_nms))\n",
    "\n",
    "  new_output.input.extend(['raw_outputs/box_encodings', 'raw_outputs/class_predictions', 'anchors'])\n",
    "  # Transform the graph to append new postprocessing op\n",
    "  input_names = []\n",
    "  output_names = ['TFLite_Detection_PostProcess']+list(additional_output_tensors)\n",
    "  transforms = ['strip_unused_nodes']\n",
    "  transformed_graph_def = TransformGraph(frozen_graph_def, input_names, output_names, transforms)\n",
    "  return transformed_graph_def\n",
    "\n",
    "\n",
    "def export_tflite_graph(pipeline_config,\n",
    "                        trained_checkpoint_prefix,\n",
    "                        output_dir,\n",
    "                        add_postprocessing_op,\n",
    "                        max_detections,\n",
    "                        max_classes_per_detection,\n",
    "                        detections_per_class=100,\n",
    "                        use_regular_nms=False,\n",
    "                        binary_graph_name='tflite_graph.pb',\n",
    "                        txt_graph_name='tflite_graph.pbtxt',\n",
    "                        additional_output_tensors=()):\n",
    "  \"\"\"Exports a tflite compatible graph and anchors for ssd detection model.\n",
    "  Anchors are written to a tensor and tflite compatible graph\n",
    "  is written to output_dir/tflite_graph.pb.\n",
    "  Args:\n",
    "    pipeline_config: a pipeline.proto object containing the configuration for\n",
    "      SSD model to export.\n",
    "    trained_checkpoint_prefix: a file prefix for the checkpoint containing the\n",
    "      trained parameters of the SSD model.\n",
    "    output_dir: A directory to write the tflite graph and anchor file to.\n",
    "    add_postprocessing_op: If add_postprocessing_op is true: frozen graph adds a\n",
    "      TFLite_Detection_PostProcess custom op\n",
    "    max_detections: Maximum number of detections (boxes) to show\n",
    "    max_classes_per_detection: Number of classes to display per detection\n",
    "    detections_per_class: In regular NonMaxSuppression, number of anchors used\n",
    "      for NonMaxSuppression per class\n",
    "    use_regular_nms: Flag to set postprocessing op to use Regular NMS instead of\n",
    "      Fast NMS.\n",
    "    binary_graph_name: Name of the exported graph file in binary format.\n",
    "    txt_graph_name: Name of the exported graph file in text format.\n",
    "    additional_output_tensors: Array of additional tensor names to output.\n",
    "      Additional tensors are appended to the end of output tensor list.\n",
    "  Raises:\n",
    "    ValueError: if the pipeline config contains models other than ssd or uses an\n",
    "      fixed_shape_resizer and provides a shape as well.\n",
    "  \"\"\"\n",
    "  tf.gfile.MakeDirs(output_dir)\n",
    "  if pipeline_config.model.WhichOneof('model') != 'ssd':\n",
    "      raise ValueError('Only ssd models are supported in tflite. Found {} in config'.format(pipeline_config.model.WhichOneof('model')))\n",
    "\n",
    "  num_classes = pipeline_config.model.ssd.num_classes\n",
    "  nms_score_threshold = {pipeline_config.model.ssd.post_processing.batch_non_max_suppression.score_threshold}\n",
    "  nms_iou_threshold = {pipeline_config.model.ssd.post_processing.batch_non_max_suppression.iou_threshold}\n",
    "  scale_values = {}\n",
    "  scale_values['y_scale'] = {pipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.y_scale}\n",
    "  scale_values['x_scale'] = {pipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.x_scale}\n",
    "  scale_values['h_scale'] = {pipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.height_scale}\n",
    "  scale_values['w_scale'] = {pipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.width_scale}\n",
    "\n",
    "  image_resizer_config = pipeline_config.model.ssd.image_resizer\n",
    "  image_resizer = image_resizer_config.WhichOneof('image_resizer_oneof')\n",
    "  num_channels = _DEFAULT_NUM_CHANNELS\n",
    "  if image_resizer == 'fixed_shape_resizer':\n",
    "      height = image_resizer_config.fixed_shape_resizer.height\n",
    "      width = image_resizer_config.fixed_shape_resizer.width\n",
    "      if image_resizer_config.fixed_shape_resizer.convert_to_grayscale:\n",
    "          num_channels = 1\n",
    "      shape = [1, height, width, num_channels]\n",
    "  else:\n",
    "      raise ValueError('Only fixed_shape_resizer is supported with tflite. Found {}'.format(image_resizer_config.WhichOneof('image_resizer_oneof')))\n",
    "\n",
    "  image = tf.placeholder(tf.float32, shape=shape, name='normalized_input_image_tensor')\n",
    "\n",
    "  detection_model = model_builder.build(pipeline_config.model, is_training=False)\n",
    "  predicted_tensors = detection_model.predict(image, true_image_shapes=None)\n",
    "  # The score conversion occurs before the post-processing custom op\n",
    "  _, score_conversion_fn = post_processing_builder.build(pipeline_config.model.ssd.post_processing)\n",
    "  class_predictions = score_conversion_fn(predicted_tensors['class_predictions_with_background'])\n",
    "\n",
    "  with tf.name_scope('raw_outputs'):\n",
    "      # 'raw_outputs/box_encodings': a float32 tensor of shape [1, num_anchors, 4]\n",
    "      #  containing the encoded box predictions. Note that these are raw\n",
    "      #  predictions and no Non-Max suppression is applied on them and\n",
    "      #  no decode center size boxes is applied to them.\n",
    "      tf.identity(predicted_tensors['box_encodings'], name='box_encodings')\n",
    "      # 'raw_outputs/class_predictions': a float32 tensor of shape\n",
    "      #  [1, num_anchors, num_classes] containing the class scores for each anchor\n",
    "      #  after applying score conversion.\n",
    "      tf.identity(class_predictions, name='class_predictions')\n",
    "  # 'anchors': a float32 tensor of shape\n",
    "  #   [4, num_anchors] containing the anchors as a constant node.\n",
    "  tf.identity(get_const_center_size_encoded_anchors(predicted_tensors['anchors']), name='anchors')\n",
    "\n",
    "  # Add global step to the graph, so we know the training step number when we\n",
    "  # evaluate the model.\n",
    "  tf.train.get_or_create_global_step()\n",
    "\n",
    "  # graph rewriter\n",
    "  is_quantized = pipeline_config.HasField('graph_rewriter')\n",
    "  if is_quantized:\n",
    "      graph_rewriter_config = pipeline_config.graph_rewriter\n",
    "      graph_rewriter_fn = graph_rewriter_builder.build(graph_rewriter_config, is_training=False)\n",
    "      graph_rewriter_fn()\n",
    "\n",
    "  if pipeline_config.model.ssd.feature_extractor.HasField('fpn'):\n",
    "      exporter.rewrite_nn_resize_op(is_quantized)\n",
    "\n",
    "  # freeze the graph\n",
    "  saver_kwargs = {}\n",
    "  if pipeline_config.eval_config.use_moving_averages:\n",
    "      saver_kwargs['write_version'] = saver_pb2.SaverDef.V1\n",
    "      moving_average_checkpoint = tempfile.NamedTemporaryFile()\n",
    "      exporter.replace_variable_values_with_moving_averages(tf.get_default_graph(), trained_checkpoint_prefix, moving_average_checkpoint.name)\n",
    "      checkpoint_to_use = moving_average_checkpoint.name\n",
    "  else:\n",
    "      checkpoint_to_use = trained_checkpoint_prefix\n",
    "\n",
    "  saver = tf.train.Saver(**saver_kwargs)\n",
    "  input_saver_def = saver.as_saver_def()\n",
    "  frozen_graph_def = exporter.freeze_graph_with_def_protos(\n",
    "      input_graph_def=tf.get_default_graph().as_graph_def(),\n",
    "      input_saver_def=input_saver_def,\n",
    "      input_checkpoint=checkpoint_to_use,\n",
    "      output_node_names=','.join(['raw_outputs/box_encodings', 'raw_outputs/class_predictions', 'anchors'] + list(additional_output_tensors)),\n",
    "      restore_op_name='save/restore_all',\n",
    "      filename_tensor_name='save/Const:0',\n",
    "      clear_devices=True,\n",
    "      output_graph='',\n",
    "      initializer_nodes='')\n",
    "\n",
    "  # Add new operation to do post processing in a custom op (TF Lite only)\n",
    "  if add_postprocessing_op:\n",
    "      transformed_graph_def = append_postprocessing_op(frozen_graph_def, max_detections, max_classes_per_detection, nms_score_threshold, nms_iou_threshold, num_classes, scale_values, detections_per_class, use_regular_nms, additional_output_tensors=additional_output_tensors)\n",
    "  else:\n",
    "      # Return frozen without adding post-processing custom op\n",
    "      transformed_graph_def = frozen_graph_def\n",
    "\n",
    "  binary_graph = os.path.join(output_dir, binary_graph_name)\n",
    "  with tf.gfile.GFile(binary_graph, 'wb') as f:\n",
    "      f.write(transformed_graph_def.SerializeToString())\n",
    "  txt_graph = os.path.join(output_dir, txt_graph_name)\n",
    "  with tf.gfile.GFile(txt_graph, 'w') as f:\n",
    "      f.write(str(transformed_graph_def))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}