{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:25:55.322960Z",
     "iopub.status.busy": "2022-01-26T05:25:55.322176Z",
     "iopub.status.idle": "2022-01-26T05:25:57.215508Z",
     "shell.execute_reply": "2022-01-26T05:25:57.215945Z"
    },
    "id": "0trJmd6DjqBZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPool1D\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "from keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.ops.confusion_matrix import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 09:15:18.891055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:18.920353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:18.920630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:18.922246: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-06 09:15:18.923652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:18.923902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:18.924123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:19.494378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:19.494671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:19.494893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 09:15:19.495102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5363 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "GPU_SET = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        if GPU_SET == 0:\n",
    "    ## 1 필요한 만큼 메모리를 런타임에 할당\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        elif GPU_SET == 1:\n",
    "    ## 2 GPU에 할당되는 전체 메모리 크기를 제한\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                    gpus[0],\n",
    "                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6144)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = 1\n",
    "SAVE = 1\n",
    "\n",
    "BATCH = 32\n",
    "EPOCH = 64\n",
    "ES = 8\n",
    "\n",
    "MIN, MAX = 0, 255\n",
    "\n",
    "CLASS = [*range(0, 19, 1)]\n",
    "CLASS\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FUNCTIONS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def log(l):\n",
    "    if DEBUG == 1: print(l)\n",
    "\n",
    "\n",
    "def draw_CM(label, predicted):\n",
    "    cm = confusion_matrix(label, predicted)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # true : false rate\n",
    "    true = 0\n",
    "    false = 0\n",
    "    for i, j in enumerate(label):\n",
    "        if j != predicted[i]:\n",
    "            false += 1\n",
    "        else: true += 1\n",
    "    classification_report = metrics.classification_report(label, predicted)\n",
    "    multilabel_to_binary_matrics = metrics.multilabel_confusion_matrix(label, predicted)\n",
    "\n",
    "    return plt.show(), print('true rate: ', true), print('false rate: ', false), print(), print('='*10,\n",
    "                                                                                                'classification_report: ',\n",
    "                                                                                                '\\n',\n",
    "                                                                                                classification_report), print(\n",
    "            '='*10, 'multilabel_to_binary_matrics by class_num: ', '\\n', '[[TN / FP] [FN / TP]]',\n",
    "            '\\n', multilabel_to_binary_matrics)\n",
    "\n",
    "\n",
    "def draw_ROC_AUC(x, y, category_names):\n",
    "    n_classes = len(category_names)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = metrics.roc_curve(y[:, i], x[:, i])\n",
    "        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y.ravel(), x.ravel())\n",
    "    roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=f'micro-average ROC curve (area = {roc_auc[\"micro\"]:0.2f})',\n",
    "             color='deeppink', linestyle=':', linewidth=1)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label=f'macro-average ROC curve (area = {roc_auc[\"macro\"]:0.2f})',\n",
    "             color='navy', linestyle=':', linewidth=1)\n",
    "\n",
    "    colors = (['purple', 'pink', 'red', 'green', 'yellow', 'cyan', 'magenta', 'blue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=1, label=f'Class {i} ROC curve (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlim([-.01, 1.0])\n",
    "    plt.ylim([0.0, 1.01])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC & AUC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    return plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DATASET"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            data  pre_label  label  location\n",
      "0  1650315681891          0      0       NaN\n",
      "1  1650315681978          0     -1       NaN\n",
      "2  1650315682128          0     -1       NaN\n",
      "3  1650315682196          0     -1       NaN\n",
      "4  1650315736806          0      0       NaN\n"
     ]
    }
   ],
   "source": [
    "data_dir = f\"/media/z/0/MVPC10/DATA/v1.1/RAW/device_03\"\n",
    "file = f\"refined_concat.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df.sort_values(by=df.keys()[0], inplace=True, ascending=True)\n",
    "log(df.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "## SHUFFLE\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# base_dir = \"out\"\n",
    "# img_list = glob(f\"{base_dir}/*.png\")\n",
    "# df = pd.read_csv(f\"{base_dir}/output(err_dropped).csv\")\n",
    "# log(df.head)\n",
    "\n",
    "# col = list(df.columns)\n",
    "# log(col)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11563/3581140263.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.iloc[i, 0] = f\"{img_dir}/{df1.iloc[i, 0]}.png\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data         /media/z/0/MVPC10/DATA/v1.2/out/1651530976724.png\n",
      "pre_label                                                    0\n",
      "label                                                        1\n",
      "location                                                   NaN\n",
      "Name: 2283, dtype: object\n",
      "['data', 'pre_label', 'label', 'location']\n"
     ]
    }
   ],
   "source": [
    "## DROP ERROR\n",
    "df1 = df[df.iloc[:, 2] > 0]\n",
    "\n",
    "## PATH TO REAL_PATH\n",
    "img_dir = f\"/media/z/0/MVPC10/DATA/v1.2/out\"\n",
    "for i in range(len(df1)):\n",
    "    df1.iloc[i, 0] = f\"{img_dir}/{df1.iloc[i, 0]}.png\"\n",
    "log(df1.iloc[1441])\n",
    "\n",
    "col = list(df1.columns)\n",
    "log(col)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "8873"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GET H,W\n",
    "sample_img = Image.open(df1.iloc[16, 0])\n",
    "img_array = np.array(sample_img, int)\n",
    "H, W = img_array.shape\n",
    "\n",
    "len(df1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PRE-PROCESS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "10000\n",
      "13000\n",
      "14000\n",
      "(8873, 60, 48, 1)\n",
      "(8873, 1)\n"
     ]
    }
   ],
   "source": [
    "## DATASET TO TENSOR\n",
    "data = []\n",
    "label = []\n",
    "for index, row in df1.iterrows():\n",
    "    try:\n",
    "        img = Image.open(row[col[0]])\n",
    "        img = data.append(list(img.getdata()))\n",
    "        lbl = label.append(row[col[1]])\n",
    "        if index%1000 == 0:  log(index)\n",
    "    except FileNotFoundError as FNFE:\n",
    "        log(FNFE)\n",
    "\n",
    "data = np.array(data)\n",
    "data = data.reshape(data.shape[0], H, W, 1)\n",
    "\n",
    "label = np.array(label)\n",
    "label = label.reshape(label.shape[0], 1)\n",
    "\n",
    "log(data.shape)\n",
    "log(label.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# ## Shuffle\n",
    "# seed = 99\n",
    "# np.random.seed(seed)\n",
    "# np.random.shuffle(data)\n",
    "# # np.random.seed(seed)\n",
    "# np.random.shuffle(label)\n",
    "\n",
    "\n",
    "## Nomalize\n",
    "# log(data[0][0])\n",
    "norm_data = data/MAX\n",
    "# norm_data = data.astype(\"float\")/MAX\n",
    "# log(norm_data[0][0])\n",
    "\n",
    "\n",
    "## TEST SPLIT\n",
    "split1 = int(len(label)*0.9)\n",
    "train_data, test_data = norm_data[:split1], norm_data[split1:]\n",
    "train_label, test_label = label[:split1], label[split1:]\n",
    "## VAL SPLIT\n",
    "split2 = int(len(label)*0.9)\n",
    "# train_data, val_data = train_data[:split2], train_data[split2:]\n",
    "# train_label, val_label = train_label[:split2], train_label[split2:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "input = Input(shape=(H, W, 1))\n",
    "\n",
    "x = Conv2D(128, (3, 3))(input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('selu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('selu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('selu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('selu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "\n",
    "# x = Conv2D(128, (3, 3))(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('selu')(x)\n",
    "# x = Dropout(.1)(x)\n",
    "#\n",
    "# x = Conv2D(64, (3, 3))(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('selu')(x)\n",
    "# x = Dropout(.1)(x)\n",
    "#\n",
    "# x = Conv2D(64, (3, 3))(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('selu')(x)\n",
    "# x = Dropout(.1)(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('selu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "#\n",
    "x = Conv2D(32, (3, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('selu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('selu')(x)\n",
    "x = Dropout(.1)(x)\n",
    "\n",
    "# x = MaxPool1D(1)\n",
    "\n",
    "x = Flatten()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Dense(8192, activation=\"selu\")(x)\n",
    "# x = Dense(4096, activation=\"selu\")(x)\n",
    "# x = Dense(2048, activation=\"selu\")(x)\n",
    "# x = Dense(1024, activation=\"selu\")(x)\n",
    "# x = Dense(512, activation=\"selu\")(x)\n",
    "# x = Dense(256, activation=\"selu\")(x)\n",
    "x = Dense(128, activation=\"selu\")(x)\n",
    "# x = Dense(64, activation=\"selu\")(x)\n",
    "x = Dense(32, activation=\"selu\")(x)\n",
    "\n",
    "x = Dropout(.5)(x)\n",
    "\n",
    "output = Dense(len(CLASS), activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### COMPILE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "## OPTIMIZER\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate=0.001,\n",
    "#         decay_steps=100000,\n",
    "#         decay_rate=0.96,\n",
    "#         staircase=True)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=10000, )\n",
    "\n",
    "        # optimizer = 'adam'\n",
    "# optimizer = Adam(0.001)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "## LOSS\n",
    "\n",
    "# loss = 'sparse_categorical_crossentropy'\n",
    "loss = SparseCategoricalCrossentropy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "## METRICS\n",
    "\n",
    "# metrics = ['accuracy']\n",
    "metrics = [SparseCategoricalAccuracy()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 60, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 58, 46, 128)       1280      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 58, 46, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 58, 46, 128)       0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 58, 46, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 56, 44, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 56, 44, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 56, 44, 128)       0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 56, 44, 128)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 54, 42, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 54, 42, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 54, 42, 128)       0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 54, 42, 128)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 52, 40, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 52, 40, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 52, 40, 128)       0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 52, 40, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 50, 38, 64)        73792     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 50, 38, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 50, 38, 64)        0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 50, 38, 64)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 48, 36, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 48, 36, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 48, 36, 32)        0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 48, 36, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 46, 34, 16)        4624      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 46, 34, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 46, 34, 16)        0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 46, 34, 16)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25024)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               3203200   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 19)                627       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,751,363\n",
      "Trainable params: 3,750,115\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRAIN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 09:18:08.266209: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-07-06 09:18:09.556356: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-07-06 09:18:09.910209: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 12s 39ms/step - loss: 3.7283 - sparse_categorical_accuracy: 0.2464 - val_loss: 4.2255 - val_sparse_categorical_accuracy: 0.3024\n",
      "Epoch 2/64\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 2.1617 - sparse_categorical_accuracy: 0.3250 - val_loss: 2.0935 - val_sparse_categorical_accuracy: 0.3431\n",
      "Epoch 3/64\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 1.8346 - sparse_categorical_accuracy: 0.3527 - val_loss: 1.5360 - val_sparse_categorical_accuracy: 0.3976\n",
      "Epoch 4/64\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 1.6101 - sparse_categorical_accuracy: 0.3936 - val_loss: 1.4526 - val_sparse_categorical_accuracy: 0.4383\n",
      "Epoch 5/64\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 1.4843 - sparse_categorical_accuracy: 0.4228 - val_loss: 1.3966 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 6/64\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.3957 - sparse_categorical_accuracy: 0.4521 - val_loss: 1.3520 - val_sparse_categorical_accuracy: 0.4721\n",
      "Epoch 7/64\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.3535 - sparse_categorical_accuracy: 0.4580 - val_loss: 1.4110 - val_sparse_categorical_accuracy: 0.4402\n",
      "Epoch 8/64\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.2971 - sparse_categorical_accuracy: 0.4748 - val_loss: 1.4380 - val_sparse_categorical_accuracy: 0.3801\n",
      "Epoch 9/64\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.2280 - sparse_categorical_accuracy: 0.5005 - val_loss: 2.2853 - val_sparse_categorical_accuracy: 0.1265\n",
      "Epoch 10/64\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 1.1651 - sparse_categorical_accuracy: 0.5346 - val_loss: 1.3886 - val_sparse_categorical_accuracy: 0.4678\n",
      "Epoch 11/64\n",
      "145/200 [====================>.........] - ETA: 1s - loss: 1.0992 - sparse_categorical_accuracy: 0.5547"
     ]
    }
   ],
   "source": [
    "## fit\n",
    "log_path = \"logs/\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=ES, mode=\"auto\", verbose=2)\n",
    "tensorboard_callback = k.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "\n",
    "history = model.fit(train_data, train_label,\n",
    "                    validation_split=0.2,\n",
    "                    # validation_data=(val_data, val_label),\n",
    "                    batch_size=BATCH,\n",
    "                    epochs=EPOCH,\n",
    "                    verbose=1,\n",
    "                    # callbacks=[es],)\n",
    "                    callbacks=[es, tensorboard_callback],)\n",
    "print(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## history to DF\n",
    "hdf = pd.DataFrame(history.history)\n",
    "hdf.keys()\n",
    "\n",
    "## plot history\n",
    "hdf.plot(figsize=(9, 6), grid=1, xlabel=\"epoch\", label=\"accuracy\")\n",
    "plt.ylim([0, 3])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# df = px.data.gapminder().query(\"continent=='Oceania'\")\n",
    "# fig = px.line(hdf, x=hdf.index, y=hdf.values, color=hdf.keys())\n",
    "# fig.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data[1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EVALUATE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_data, test_label, verbose=1)\n",
    "\n",
    "predict = model.predict(test_data)\n",
    "predicted = np.argmax(predict, axis=1)\n",
    "\n",
    "n = 10\n",
    "print(predicted[:n])\n",
    "print(test_label[:n].reshape([n]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predict = model.predict(train_data)\n",
    "# predicted = np.argmax(predict, axis=1)\n",
    "#\n",
    "# draw_CM(train_label, predicted)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## CM\n",
    "draw_CM(test_label, predicted)\n",
    "\n",
    "## ROC, AUC\n",
    "x = label_binarize(predicted, classes=CLASS)\n",
    "y = label_binarize(test_label, classes=CLASS)\n",
    "draw_ROC_AUC(x, y, CLASS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 10\n",
    "# N = len(predicted)\n",
    "for i in range(N):\n",
    "    NUM = i\n",
    "\n",
    "    size = 10\n",
    "    test_img = Image.fromarray((test_data[NUM]*255).reshape(H,W)).convert('L').resize((W*size, H*size))\n",
    "    display(test_img)\n",
    "\n",
    "    log(f\"predicted: {predicted[NUM]}, label: {test_label[NUM][0]}\")\n",
    "    log(f\"difference: {abs(predicted[NUM]-test_label[NUM][0])}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SAVE == 1:\n",
    "  file_name = \"model/mvpc10_\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  model_format = \".h5\"\n",
    "  model_name = file_name+model_format\n",
    "  model.save(model_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}