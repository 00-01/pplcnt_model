{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as T\n",
    "import numpy\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False);\n",
    "import itertools\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cocodataset/panopticapi.git\r\n",
      "  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-req-build-akk3yate\r\n",
      "  Running command git clone -q https://github.com/cocodataset/panopticapi.git /tmp/pip-req-build-akk3yate\r\n",
      "  Resolved https://github.com/cocodataset/panopticapi.git to commit 7bb4655548f98f3fedc07bf37e9040a992b054b0\r\n",
      "Requirement already satisfied: numpy in /home/z/anaconda3/lib/python3.9/site-packages (from panopticapi==0.1) (1.22.3)\r\n",
      "Requirement already satisfied: Pillow in /home/z/anaconda3/lib/python3.9/site-packages (from panopticapi==0.1) (9.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/cocodataset/panopticapi.git\n",
    "\n",
    "import panopticapi\n",
    "from panopticapi.utils import id2rgb, rgb2id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "CLASSES = ['person', ]\n",
    "# CLASSES = ['N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear','zebra', 'giraffe', 'Backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', ‘snowboard', 'sportsball', 'kite', 'baseballbat','baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', ‘chair', 'couch', 'pottedplant', 'bed', 'N/A', 'diningtable', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', ‘toothbrush']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CLASSES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m coco2d2 \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      3\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mCLASSES\u001B[49m):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m c \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mN/A\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      6\u001B[0m         coco2d2[i] \u001B[38;5;241m=\u001B[39m count\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CLASSES' is not defined"
     ]
    }
   ],
   "source": [
    "# Enumerate the above classes(Detectron2 model uses different numbering convention so we need to change it)\n",
    "coco2d2 = {}\n",
    "count = 0\n",
    "for i, c in enumerate(CLASSES):\n",
    "    if c != \"N/A\":\n",
    "        coco2d2[i] = count\n",
    "        count += 1\n",
    "\n",
    "# Perform standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([T.Resize(800), T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "# Load a pre-trained model from torch hub and request the post-processor\n",
    "model, postprocessor = torch.hub.load('facebookresearch/detr', 'detr_resnet101_panoptic', pretrained=True, return_postprocessor=True, num_classes=250)\n",
    "\n",
    "model.eval()\n",
    "# Retrieve an image from the validation\n",
    "# set of COCO dataset for testing purpose\n",
    "url = \"http://images.cocodataset.org/val2017/000000281759.jpg\"\n",
    "im = Image.open(requests.get(url, stream=True).raw)\n",
    "# Mean-std normalize the input testing image(batch-size: 1)\n",
    "img = transform(im).unsqueeze(0)\n",
    "out = model(img)\n",
    "# Compute the probability score for each possible class, excluding the “no-object” class (the last one)\n",
    "scores = out[\"pred_logits\"].softmax(-1)[..., :-1].max(-1)[0]\n",
    "\n",
    "# Threshold the confidence to only masks with high confidence > 0/85\n",
    "keep = scores > 0.85\n",
    "\n",
    "# Plot the masks satisfying the confidence level condition\n",
    "ncols = 5\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=math.ceil(keep.sum().item()/ncols), figsize=(18, 10))\n",
    "for line in axs:\n",
    "    for a in line:\n",
    "        a.axis('off')\n",
    "for i, mask in enumerate(out[\"pred_masks\"][keep]):\n",
    "    ax = axs[i//ncols, i%ncols]\n",
    "    ax.imshow(mask, cmap=\"cividis\")\n",
    "    ax.axis('off')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Merge the individual predictions obtained by running the above lines of code into a unified panoptic segmentation.For that, we use DETR’s postprocessor.\n",
    "# The post-processor requires as input the target size of predictions(image sizehere)\n",
    "result = postprocessor(out, torch.as_tensor(img.shape[-2:]).unsqueeze(0))[0]\n",
    "\n",
    "# Visualize the panoptic segmentation’s results\n",
    "# The segmentation is stored in a special-format png\n",
    "panoptic_seg = Image.open(io.BytesIO(result['png_string']))\n",
    "panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8).copy()\n",
    "\n",
    "# Retrieve the instance id corresponding to each mask\n",
    "panoptic_seg_id = rgb2id(panoptic_seg)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'panoptic_seg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Color each mask individually and plot the visualization\u001B[39;00m\n\u001B[1;32m      2\u001B[0m palette \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m255\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m----> 3\u001B[0m \u001B[43mpanoptic_seg\u001B[49m[:, :, :] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mid\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(panoptic_seg_id\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m      5\u001B[0m     panoptic_seg[panoptic_seg_id \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mid\u001B[39m] \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39masarray(\u001B[38;5;28mnext\u001B[39m(palette))\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m255\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'panoptic_seg' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Color each mask individually and plot the visualization\n",
    "palette = [255,0,0]\n",
    "panoptic_seg[:, :, :] = 0\n",
    "for id in range(panoptic_seg_id.max()+1):\n",
    "    panoptic_seg[panoptic_seg_id == id] = numpy.asarray(next(palette))*255\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(panoptic_seg)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use Detectron2’s plotting utilities to better visualize the above panoptic segmentation results.\n",
    "# !pip install detectron2 == 0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "# Extract the segments information and the panoptic result from DETR’s prediction\n",
    "from copy import deepcopy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "segments_info = deepcopy(result[\"segments_info\"])\n",
    "\n",
    "# Store the panoptic predictions in a special format png\n",
    "panoptic_seg = Image.open(io.BytesIO(result['png_string']))\n",
    "final_w, final_h = panoptic_seg.size\n",
    "\n",
    "# Convert the png into segment id map\n",
    "panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8)\n",
    "panoptic_seg = torch.from_numpy(rgb2id(panoptic_seg))\n",
    "\n",
    "# Change Detectron2’s numbering to appropriate class id’s\n",
    "meta = MetadataCatalog.get(\"coco_2017_val_panoptic_separated\")\n",
    "for i in range(len(segments_info)):\n",
    "    c = segments_info[i][\"category_id\"]\n",
    "    segments_info[i][\"category_id\"] = meta.thing_dataset_id_to_contiguous_id[c] if segments_info[i][\"isthing\"] else meta.stuff_dataset_id_to_contiguous_id[c]\n",
    "\n",
    "# Visualize the improved prediction results\n",
    "v = Visualizer(numpy.array(im.copy().resize((final_w, final_h)))[:, :, ::-1], meta, scale=1.0)\n",
    "v._default_font_size = 20\n",
    "v = v.draw_panoptic_seg_predictions(panoptic_seg, segments_info, area_threshold=0)\n",
    "cv2.imshow(v.get_image())\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}